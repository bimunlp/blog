<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Deep Learning</title>
  
  <subtitle>深度学习</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-17T12:30:09.126Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Scott Liu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>chapter 6 Hidden Variables</title>
    <link href="http://yoursite.com/2019/01/17/chapter-6-Hidden-Variables/"/>
    <id>http://yoursite.com/2019/01/17/chapter-6-Hidden-Variables/</id>
    <published>2019-01-17T11:53:43.000Z</published>
    <updated>2019-01-17T12:30:09.126Z</updated>
    
    <content type="html"><![CDATA[<p>There are situations where parts of the outputs are not available in training data. In such case, we need to consider models that contain hidden variables.</p><a id="more"></a><!-- toc --><ul><li><a href="#chapter-6">chapter 6</a></li><li><a href="#hidden-variables">Hidden Variables</a><ul><li><a href="#61">6.1</a></li><li><a href="#expectation-maximization">Expectation Maximization</a></li><li><a href="#em-algorithm-for-k-means-clustering">EM algorithm for K-means clustering</a></li><li><a href="#611-hard-em">6.1.1 Hard EM</a></li><li><a href="#hard-em">Hard EM</a></li><li><a href="#k-means-vs-hard-em">K-means v.s. Hard EM</a></li><li><a href="#612-soft-em">6.1.2 Soft EM</a></li><li><a href="#613-relationships-between-supervised-mle-and-em">6.1.3 Relationships between supervised MLE and EM</a></li><li><a href="#62">6.2</a></li><li><a href="#em-derivation-and-kl-divergence">EM Derivation and KL-Divergence</a></li><li><a href="#622-em-deriviation-using-numerical-optimization">6.2.2 EM deriviation using Numerical Optimization</a></li><li><a href="#63">6.3</a></li><li><a href="#application-of-em">Application of EM</a></li><li><a href="#em-algorithm-summary">EM Algorithm Summary</a></li><li><a href="#631-unsupervised-naive-bayes-model">6.3.1 Unsupervised Naive Bayes model</a></li><li><a href="#632-ibm-model-1">6.3.2 IBM Model 1</a></li><li><a href="#word-alignment">Word alignment</a></li><li><a href="#em-training">EM training</a></li><li><a href="#ibm-model-1">IBM model 1</a></li><li><a href="#633-probabilistic-latent-semantic-analysis">6.3.3 Probabilistic Latent Semantic Analysis</a></li><li><a href="#plsa-applications">PLSA Applications</a></li><li><a href="#summary">Summary</a></li></ul></li></ul><!-- tocstop --><h1><span id="chapter-6">chapter 6</span></h1><h1><span id="hidden-variables">Hidden Variables</span></h1><hr><p><img src="/home/scott/Downloads/hidden.png" alt=""><br><strong>Expextation maximization (EM)</strong></p><ul><li>unsupervised Naive Bayes model</li><li>IBM model 1</li><li>probabilistic latent semantic analysis (PLSA) model</li></ul><hr><h2><span id="61">6.1</span></h2><h2><span id="expectation-maximization">Expectation Maximization</span></h2><hr><p>Observation on K-means clustering<br><img src="/home/scott/Downloads/kmean.png" alt=""><br>EM processes:</p><ul><li>expectation step: <ul><li>random point-cluster assignment</li></ul></li><li>maximization step:<ul><li>minimizes vector distances to the centroids</li></ul></li></ul><hr><h2><span id="em-algorithm-for-k-means-clustering">EM algorithm for K-means clustering</span></h2><p>#</p><ul><li>Observed points : $O = \left. \left\{ o _ { i } \right\} \right| _ { i = 1 } ^ { N }$</li><li>Learning objective : minimising $L ( O ) = \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { K } \mathbf { h } _ { i k } \left| o _ { i } - c _ { k } \right| ^ { 2 }$ ,where $c_{k}$ is  the centroid of cluster $k$, and $h_{ik}$ is an indicator variable.</li><li>Notations :<ul><li>Hidden variable $H = \left. \left\{ \mathbf { h } _ { i k } \right\} \right| _ { i = 1 , k = 1 } ^ { N , K }$ ,</li><li>Parameter  $\Theta = \left. \left\{ c _ { k } \right\} \right| _ { k = 1 } ^ { K }$ </li></ul></li></ul><hr><ul><li>Training process :<ul><li>Iteration over $H$: $H ^ { t } \leftarrow { \arg \min } \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { K } \mathbf { h } _ { i k } \left| o _ { i } - c _ { k } ^ { t } \right| ^ { 2 }$</li><li>Iteration over $\Theta$: $\Theta ^ { t + 1 } \leftarrow { \arg \min } \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { K } \mathbf { h } _ { i k } ^ { t } \left| o _ { i } - c _ { k } \right| ^ { 2 }$</li></ul></li><li>The optimal value : $c _ { k } ^ { t + 1 } = \frac { \sum _ { i = 1 } ^ { N } \mathbf { h } _ { i k } ^ { t } O _ { i } } { \sum _ { i = 1 } ^ { N } \mathbf { h } _ { i k } ^ { t } }$ , which is the average of all points in cluster $k$.</li></ul><hr><h2><span id="611-hard-em">6.1.1 Hard EM</span></h2><p>General form of EM algorithm<br>#<br>Notations:</p><ul><li>Observed data $O$</li><li>Hidden data $H$</li><li>Model parameter $\Theta$</li><li>Model $P(O,H|\Theta)$</li></ul><p>Trainging objective with hidden variables:</p><ul><li>Maximising $L(\Theta)=logP(O|\Theta)=log\sum_{H}P(O,H|\Theta)$</li></ul><hr><h2><span id="hard-em">Hard EM</span></h2><p><img src="/home/scott/Desktop/hardem.png" alt=""><br>Using a single optimal configuration of $H$, hard EM optimizes<br>$L ( \Theta ) = \log \max _ { H } P ( O , H | \Theta )$<br>The optimum $\Theta^{<em>}$ given by hard EM is<br>$\Theta^</em>\leftarrow argmax_{\Theta}max_{H}logP(O|\Theta)$</p><hr><h2><span id="k-means-vs-hard-em">K-means v.s. Hard EM</span></h2><p><img src="/home/scott/Downloads/vs.png" alt=""><br>K-means is a type of hard EM algorithm.</p><hr><h2><span id="612-soft-em">6.1.2 Soft EM</span></h2><p>Soft EM considers all possible values of hidden variables.<br><img src="/home/scott/Desktop/softem.png" alt=""><br>$P(h|o_{i},\Theta^{t}),h \in H$ is the assignment distribution of $H$.<br>$Q(\Theta,\Theta^t)$ is called the <strong>Q-function</strong>.</p><p>Hard EM is a special case of soft EM.</p><hr><h2><span id="613-relationships-between-supervised-mle-and-em">6.1.3 Relationships between supervised MLE and EM</span></h2><p>We can turn EM algorithm to MLE in supervised settings.</p><ul><li>suppose each $o_{i}$ has a supervised label $y_{i}$</li><li><p>defining<br>$P ( h | o _ { i } , \Theta ^ { t } ) = \left\{ \begin{array} { l } { 1 \text { if } h = y _ { i } } \ { 0 \text { otherwise } } \end{array} \right.$</p><p>$\begin{aligned} Q \left( \Theta , \Theta ^ { t } \right) &amp; = \sum _ { i = 1 } ^ { N } \sum _ { \mathbf { h } \in H } P ( \mathbf { h } | o _ { i } , \Theta ^ { t } ) \log P \left( o _ { i } , \mathbf { h } | \Theta \right) \ &amp; = \sum _ { i = 1 } ^ { N } \log P \left( o _ { i } , y _ { i } | \Theta \right) \end{aligned}$</p><p>which is exactly the maximum log-likelihood training objective.</p></li></ul><hr><h2><span id="62">6.2</span></h2><h2><span id="em-derivation-and-kl-divergence">EM Derivation and KL-Divergence</span></h2><hr><p> Jensen inequality<br> <img src="/home/scott/Downloads/Convex_b.png" alt=""><br> for convex functions, $E(g(\mu))\ge g(E(\mu))$,<br> for concave functions, $E(g(\mu))\le g(E(\mu)).$</p><hr><p> Using Jensen inequality<br> $L(\Theta)=log\sum_{h}P(O,h|\Theta)\ge$ $\sum _ { h } P _ { C } ( h ) \log \frac { P ( O , h | \Theta ) } { P _ { C } ( h ) }=F(\Theta,Pc)$,<br> $F(\Theta,Pc)$ is a lower bound of $L(\Theta)$</p><p>Also,<br> $F(\Theta,Pc)= L ( \Theta ) - K L \left( P _ { C } ( h ) , P ( h | O , \Theta ) \right)$</p><blockquote><p>KL-divergence is always non-negative</p><blockquote><p>$KL(P,Q)$ is zero if and only if $P=Q$</p><p>To make the bound as tight as possible,<br>$Pc(h)=P(h|O,\Theta)$<br>In this scenario, $F(\Theta,Pc)=L(\Theta)$</p></blockquote></blockquote><hr><h2><span id="622-em-deriviation-using-numerical-optimization">6.2.2 EM deriviation using Numerical Optimization</span></h2><p> Another way to maximizes $F(\Theta,Pc)$<br> <strong>Coordinate ascent</strong></p><ul><li>Expectation step.<br>finds a optimum distributioon $Pc(H)$ that maximizes $F(\Theta^t,Pc)$</li><li>Maximization step.<br>finds the optimum $\Theta^{t+1}$ for $F(\Theta,P^{t+1}_{c})$</li><li>Convergence.<br>after every iteration of E-step and M-step,<br> $L(\Theta^{t+1})-L(\Theta)\ge0$,<br> $L(\Theta)$ is a monotonically increasing function, EM is guaranteed to converge to local optimums.</li></ul><hr><h2><span id="63">6.3</span></h2><h2><span id="application-of-em">Application of EM</span></h2><hr><h2><span id="em-algorithm-summary">EM Algorithm Summary</span></h2><p> To apply EM to a certain task, we need three particular steps:</p><ol><li>obtain the complete data likelihood $P(O,H|\Theta)$</li><li>compute $P(H|O,\Theta)$<br>$P(H|O,\Theta)=\frac{P(O,H|\Theta)}{P(O|\Theta)}$</li><li>maximize $Q(\Theta,\Theta^{t})$<br>$Q \left( \Theta , \Theta ^ { t } \right) = \sum _ { h } P ( h | O , \Theta ^ { t } ) \log P ( O , h | \Theta )$</li></ol><hr><h2><span id="631-unsupervised-naive-bayes-model">6.3.1 Unsupervised Naive Bayes model</span></h2><p> Hidden variables h: output document class,<br> for document $d_{i}$, the complete data likelihood is </p><p>$P \left( d _ { i } , \mathbf { h } | \Theta ^ { t } \right) = P ( \mathbf { h } | \Theta ^ { t } ) P \left( d _ { i } | \mathbf { h } , \Theta ^ { t } \right) = P ( \mathbf { h } | \Theta ^ { t } ) \prod _ { i = 1 } ^ { \left| d _ { i } \right| } P \left( w _ { i } | \mathbf { h } , \Theta ^ { t } \right)$</p><p>Then we can calculate </p><p>$P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) = \frac { P \left( d _ { i } , \mathbf { h } | \Theta ^ { t } \right) } { \sum _ { \mathbf { h } } P \left( d _ { i } , \mathbf { h } | \Theta ^ { t } \right) } = \frac { P ( \mathbf { h } | \Theta ^ { t } ) \prod _ { i = 1 } ^ { \left| d _ { i } \right| } P \left( w _ { i } | \mathbf { h } , \Theta ^ { t } \right) } { \sum _ { \mathbf { h } } P ( \mathbf { h } | \Theta ^ { t } ) \prod _ { i = 1 } ^ { \left| d _ { i } \right| } P \left( w _ { i } | \mathbf { h } , \Theta ^ { t } \right) }$</p><p>Maximize the expectation,</p><p>$Q \left( \Theta , \Theta ^ { t } \right) = \sum _ { i = 1 } ^ { N } \sum _ { \mathbf { h } } P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) \log P \left( d _ { i } , \mathbf { h } | \Theta \right)$</p><hr><p>Finding $\arg \max _ { \Theta } Q \left( \Theta , \Theta ^ { t } \right)$ s.t. $\sum _ { \mathbf { h } } P ( \mathbf { h } | \Theta ) = 1$ and $\sum _ { \mathbf { w } \in V } P ( \mathbf { w } | \mathbf { h } , \Theta ) = 1$</p><p>Using Lagrangian multiplier,</p><p>We derive that,</p><p>$P ( \mathbf { h } | \Theta ) = \frac { \sum _ { i = 1 } ^ { N } P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) } { N }$</p><p>$P ( \mathbf { w } | \mathbf { h } , \Theta ) =$ $\frac { \sum _ { i = 1 } ^ { N } P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) \sum _ { j = 1 } ^ { \left| d _ { i } \right| } \delta \left( w _ { j } , w \right) } { \sum _ { i = 1 } ^ { N } P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) \left| d _ { i } \right| }$</p><p>soft EM can be executed now.</p><hr><h2><span id="632-ibm-model-1">6.3.2 IBM Model 1</span></h2><p>A probabilistic model for Machine Translation (MT) </p><ul><li>source sentence X</li><li>target language translation Y</li><li>source word $X = x _ { 1 } x _ { 2 } \ldots x _ { | X | }$</li><li>Target word $Y = y _ { 1 } y _ { 2 } \dots y _ { | Y | }$</li></ul><p>Bayes rule: $P ( Y | X ) = \frac { P ( X | Y ) P ( Y ) } { P ( X ) } \propto P ( X | Y ) P ( Y )$</p><ul><li>Language model : $P(Y)$  ensure fluency</li><li>Translation model : $P(X|Y)$  ensure adequacy</li></ul><p>Using probability chain rule and assuming each source word $x_{i}$ is conditionally dependent to only one target word $y_{a_{i}}$, we have</p><p>$P(X|Y)$ $= P \left( x _ { 1 } | y _ { a _ { 1 } } \right) P \left( x _ { 2 } | y _ { a _ { 2 } } \right) \ldots P \left( x _ { | X | } | y _ { a _ { | X | } } \right)$</p><hr><h2><span id="word-alignment">Word alignment</span></h2><p>Word alignment $A = \left. \left\{ a _ { i } \right\} \right| _ { i = 1 } ^ { | X | }$ , $a_{i}$ denotes the index of the target word that the $i$-th source word translates to.<br><img src="/home/scott/Desktop/alignment.png" alt=""><br>types of word alignment between sentence translation pairs:</p><p>Monotonic , Non-monotonic , Many-to-one , Null </p><hr><h2><span id="em-training">EM training</span></h2><ul><li>Observation variable: $O=(X,Y)$ ,i.e. sentence translation pairs $D = \left. \left\{ \left( X _ { i } , Y _ { i } \right) \right\} \right| _ { i = 1 } ^ { N }$</li><li>Hidden variable: $H=A$ , i.e. word alignment $A_{i}$</li></ul><p>$\begin{aligned} P ( A , X | Y ) &amp; = P ( A | Y ) P ( X | A , Y ) \ &amp; = \frac { \prod _ { i = 1 } ^ { | X | } P \left( x _ { i } | y _ { a _ { i } } \right) } { # ( A \text { between } X \text { and } Y ) } \ &amp; = \frac { \prod _ { i = 1 } ^ { | X | } P \left( x _ { i } | y _ { a _ { i } } \right) } { ( | Y | + 1 ) ^ { | X | } } \end{aligned}$</p><p>$\begin{aligned} P ( A | X , Y ) &amp; = \frac { P ( A , X | Y ) } { P ( X | Y ) } \ &amp; = \frac { \prod _ { i = 1 } ^ { | X | } P \left( x _ { i } | y _ { a _ { i } } \right) } { \prod _ { i = 1 } ^ { | X | } \sum _ { j = 0 } ^ { | Y | } P \left( x _ { i } | y _ { j } \right) } \ &amp; = \prod _ { i = 1 } ^ { | X | } \frac { P \left( x _ { i } | y _ { a _ { i } } \right) } { \sum _ { j = 0 } ^ { | Y | } P \left( x _ { i } | y _ { j } \right) } \end{aligned}$</p><hr><p>After knowing $P ( A | X , Y )$ and $P ( A , X | Y )$ , we can define the Q-function for sentence translation pair $(X,Y)$:</p><p>$\begin{aligned} Q \left( \Theta , \Theta ^ { t } \right) &amp; = \sum _ { A } P ( A | X , Y , \Theta ^ { t } ) \log P ( A , X | Y , \Theta ) \ &amp; = \sum _ { A } P ( A | X , Y , \Theta ^ { t } ) \log \frac { \prod _ { i = 1 } ^ { | X | } P \left( x _ { i } | y _ { a _ { i } } , \Theta \right) } { ( | Y | + 1 ) ^ { | X | } } \end{aligned}$</p><p>Applying Lagrangian function, </p><p>The expected alignment between a word translation pair </p><p>EXPECTEDALIGN$( \mathbf { x } , \mathbf { y } , X , Y )$ $= \sum _ { A } P ( A | X , Y ) \cdot \sum _ { k = 1 } ^ { | X | } \delta \left( \mathbf { x } , x _ { k } \right) \delta \left( \mathbf { y } , y _ { a _ { k } } \right)$</p><p>$= \frac { P ( \mathbf { x } | \mathbf { y } ) } { \sum _ { j = 0 } ^ { | Y | } P ( \mathbf { x } | y _ { j } ) } \sum _ { i = 1 } ^ { | X | } \delta \left( \mathbf { x } , x _ { i } \right) \sum _ { j = 0 } ^ { | Y | } \delta \left( \mathbf { y } , y _ { j } \right)$</p><p>EXPECTEDALIGN $( \mathbf { x } , \mathbf { y } , X , Y )$ represents a soft count.</p><hr><h2><span id="ibm-model-1">IBM model 1</span></h2><p>Word alignment<br><img src="/home/scott/Desktop/algorithms.png" alt=""><br>IBM models are word-based machine translation models</p><hr><h2><span id="633-probabilistic-latent-semantic-analysis">6.3.3 Probabilistic Latent Semantic Analysis</span></h2><p><img src="/home/scott/Downloads/topic.png" alt=""><br>PLSA is a generative model for document semantic analysis.<br> Topics are hidden variables .</p><ul><li>Document-topic distribution $P(h|d_{i})$</li><li>Topic-word distribution $P(w|h)$</li></ul><hr><p> <img src="/home/scott/Desktop/plsa.png" alt=""><br> For every document $d$, for every position $l$:</p><ol><li>select a document $d_{i}$ from $P(d_{i})$</li><li>generate a topic $h_{l}$ from $P(h|d)$</li><li>generate a word $w_{l}$ from $P(w|h_{l})$</li></ol><p>The complete data likelihood of word-document pair <w,h> under d:<br>$P(w,h|d)=P(h|d)P(w|h,d)$<br>$P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) = \frac { P \left( \mathbf { h } , d _ { i } , \mathbf { w } | \Theta ^ { t } \right) } { P \left( d _ { i } , \mathbf { w } | \Theta ^ { t } \right) }$</w,h></p><p>$= \frac { P ( \mathbf { h } | d _ { i } , \Theta ^ { t } ) P ( \mathbf { w } | \mathbf { h } , \Theta ^ { t } ) } { \sum _ { \mathbf { h } ^ { \prime } } P \left( \mathbf { h } ^ { \prime } | d _ { i } , \Theta ^ { t } \right) P ( \mathbf { w } | \mathbf { h } ^ { \prime } , \Theta ^ { t } ) }$</p><p>The Q-function:</p><p>$Q \left( \Theta , \Theta ^ { t } \right) = \sum _ { i = 1 } ^ { N } \sum _ { \mathbf { w } \in d _ { i } } \sum _ { \mathbf { h } } P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) \log P \left( \mathbf { h } , d _ { i } , \mathbf { w } | \Theta \right)$</p><p>$= \sum _ { i = 1 } ^ { N } \sum _ { \mathbf { w } \in V } C \left( \mathbf { w } , d _ { i } \right) \sum _ { \mathbf { h } } P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) [ \log P ( \mathbf { h } | d _ { i } , \Theta ) + \log P ( \mathbf { w } | \mathbf { h } , \Theta ) ]$</p><hr><p>Define a Lagrangian function</p><p>$\Lambda ( \Theta , \lambda ) = Q \left( \Theta , \Theta ^ { t } \right) - \sum _ { i } \lambda _ { d _ { i } } \left( \sum _ { \mathbf { h } } P ( \mathbf { h } | d _ { i } , \Theta ) - 1 \right)$ $- \sum _ { \mathbf { h } } \lambda _ { \mathbf { h } } \left( \sum _ { \mathbf { w } } P ( \mathbf { w } | \mathbf { h } , \Theta ) - 1 \right)$</p><p>consider $\frac { \partial \Lambda ( \Theta , \lambda ) } { \partial P ( \mathbf { h } | d _ { i } , \Theta ) }=0$ and $\sum _ { \mathbf { h } } P ( \mathbf { h } | d _ { i } , \Theta ) - 1 = 0$</p><p>$P ( \mathbf { h } | d _ { i } , \Theta )=$$\frac { \sum _ { \mathbf { w } \in V } C \left( \mathbf { w } , d _ { i } \right) P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) } { \sum _ { \mathbf { w } \in V } C \left( \mathbf { w } , d _ { i } \right) }$</p><p>$P ( \mathbf { w } | \mathbf { h } , \Theta ) = \frac { \sum _ { i = 1 } ^ { N } C \left( \mathbf { w } , d _ { i } \right) P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) } { \sum _ { i = 1 } ^ { N } \sum _ { \mathbf { w } \in V } C \left( \mathbf { w } , d _ { i } \right) P ( \mathbf { h } | d _ { i } , \mathbf { w } , \Theta ^ { t } ) }$</p><hr><h2><span id="plsa-applications">PLSA Applications</span></h2><ul><li>Keyword extraction</li><li>Information retrieval</li><li>Recommendation systems</li></ul><hr><h2><span id="summary">Summary</span></h2><ul><li>The concept of hidden variables</li><li>Hard and soft variations of the Expectation Maximization (EM) algorithm</li><li>THe correlation between EM and MLE for training probabilistic models</li><li>EM for unsupervised text classification</li><li>IBM model 1 for statistical machine translation</li><li>Probabilistic latent semantic allocation</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;There are situations where parts of the outputs are not available in training data. In such case, we need to consider models that contain hidden variables.&lt;/p&gt;
    
    </summary>
    
      <category term="自然语言处理" scheme="http://yoursite.com/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="自然语言处理" scheme="http://yoursite.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="隐变量" scheme="http://yoursite.com/tags/%E9%9A%90%E5%8F%98%E9%87%8F/"/>
    
      <category term="hidden variables" scheme="http://yoursite.com/tags/hidden-variables/"/>
    
  </entry>
  
  <entry>
    <title>什么是深度学习？</title>
    <link href="http://yoursite.com/2019/01/16/No%202%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F/"/>
    <id>http://yoursite.com/2019/01/16/No 2 什么是深度学习？/</id>
    <published>2019-01-16T13:32:50.000Z</published>
    <updated>2019-01-17T13:10:02.529Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习与深度学习基础教程</p><p><img src="http://plgrq7ioi.bkt.clouddn.com/cover_1.jpg" alt="cover_1"></p><p>这篇文章将要回答什么是深度学习这个问题．</p><p>整个系列课程会涵盖深度学习领域的众多主题，我们会用很多篇文章来充分解释这些课题，以及它们的应用领域和技术实现。</p><a id="more"></a><!-- toc --><ul><li><a href="#深度学习概念解析">深度学习概念解析</a><ul><li><a href="#什么是深度学习">什么是深度学习？</a></li><li><a href="#深度学习中的深度指的是什么">深度学习中的＂深度＂指的是什么？</a></li></ul></li></ul><!-- tocstop --><p><img src="http://plgrq7ioi.bkt.clouddn.com/image_2.png" alt="image_2"></p><h2><span id="深度学习概念解析">深度学习概念解析</span></h2><h3><span id="什么是深度学习">什么是深度学习？</span></h3><p>这篇文章将要回答什么是深度学习这个问题．</p><p>整个系列课程会涵盖深度学习领域的众多主题，我们会用很多篇文章来充分解释这些课题，以及它们的应用领域和技术实现。</p><p>在这个深度学习系列中所有的文章按特定顺序发表，一些文章中某些概念是基于之前讨论过的概念之上，因此如果你还不熟悉我们正在使用的某些术语或示例，请务必查看先前的文章。</p><p>让我们给出深度学习的定义。</p><blockquote><p>深度学习是机器学习的一个子领域，它所使用的算法是由人类大脑神经网络结构和功能所启发。</p></blockquote><p>我们现在所讲的深度学习，同样采用从数据中学习的算法，就像我们在上一篇关于机器学习的文章中所讨论的那样。 然而，这里的学习算法或模型是基于大脑神经网络的结构和功能。</p><p>我们在深度学习中使用的神经网络不是真正的生物神经网络。 他们只是与生物神经网络共享一些特征，因此，我们称之为人工神经网络（ANNs）。</p><p>我们也经常使用其他术语来指代人工神经网络。 在深度学习领域，人工神经网络（ANN）这个术语有时候也用下面的一些表达：</p><ul><li>网络(net)</li><li>神经网络(neural net)</li><li>模型(model)</li></ul><p><img src="http://plgrq7ioi.bkt.clouddn.com/layers.png" alt="a simple artificial neural network or ANN"></p><h3><span id="深度学习中的深度指的是什么">深度学习中的＂深度＂指的是什么？</span></h3><p>要理解深度学习中的＂深度＂指的是什么，我们首先需要了解人工神经网络的结构。 我们会发现，深度学习使用了一种我们称之为深网(deep net)或深层人工神经网络(deep artificial neural network)的特殊人工神经网络。</p><p>在下一篇关于人工神经网络的文章中，我们将学习如何构建人工神经网络，这将为我们提供理解人工神经网络如何成为深度人工神经网络所需的知识。</p><p>现在，你需要了解以下内容：</p><ol><li>ANN是使用我们称之为神经元的方法构建的</li><li>人工神经网络中的神经元通过层(layer)的方法构建。</li><li>ANN中除了输入层(input layer)和输出层(output layer)之外的所有层都称为隐藏层(hidden layers)。</li><li>如果ANN具有多个隐藏层，则称该ANN为深度ANN</li></ol><p><img src="http://plgrq7ioi.bkt.clouddn.com/layers4.png" alt="deep neural network with 4 layers"></p><p>总结一下，深度学习使用具有多个隐藏层的ANN结构。 在学习过程中请牢记这一点，随着我们对深度学习理解的加深，我们会越来越明白这一点。 期待下个文章跟你相遇！</p><span class="highlight-text purple">公众微信：友邻学社关注获取更多内容</span><p><img src="http://plgrq7ioi.bkt.clouddn.com/qrcode.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习与深度学习基础教程&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://plgrq7ioi.bkt.clouddn.com/cover_1.jpg&quot; alt=&quot;cover_1&quot;&gt;&lt;/p&gt;
&lt;p&gt;这篇文章将要回答什么是深度学习这个问题．&lt;/p&gt;
&lt;p&gt;整个系列课程会涵盖深度学习领域的众多主题，我们会用很多篇文章来充分解释这些课题，以及它们的应用领域和技术实现。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
