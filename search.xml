<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习中的半监督学习(semi-supervised learning)</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-semi-supervised-learning.html"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-semi-supervised-learning.html</url>
      
        <content type="html"><![CDATA[<p>这篇文章我们了解<em>半监督学习</em>的概念 。</p><p>半监督学习在监督学习和无监督学习之间占据中间地位。</p><p>回顾以前学过的内容， <a href="http://yiyouls.com/2019/02/22/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-supervised-learning/">监督学习</a>是在训练中模型从被标记的数据集中学习。 <a href="https://yiyouls.com/2019/02/23/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-unsupervised-learning/">无监督学习</a>是从未被标记的数据中学习。那半监督学习又是怎样的呢？</p><p><em>半监督学习</em>将有监督和无监督学习技术结合起来，在我们使用半监督学习的情况下，我们会同时使用<em>标记</em>和<em>未标记的</em> 数据。</p><a id="more"></a><p>让我们通过一个例子来深入理解这个概念。</p><h4><span id="大规模未标记数据集">大规模未标记数据集</span></h4><p>假设我们有大量用来训练模型的未标记数据集，手动标记所有这些数据是不现实的。</p><p>但是我们可以手动标记这个大型数据集的某些部分，并使用该部分来训练模型。</p><p><img src="http://cdn.yiyouls.com/cluster-3-groups.png" alt=""></p><p>实际上，这是大部分情况下神经网络标记大规模数据方式。不过，既然我们已经搜集到了大量数据，但只标记了这些数据的一小部分，那么将所有其他未标记数据扔掉就会很浪费。</p><p>毕竟，训练模型的数据越多，模型就会变得越好，越强大。我们可以想办法利用数据集中剩余的未标记数据．</p><p>我们可以使用一种属于半监督学习的技术，称为<em>伪标签(pseudo-labeling)</em>。</p><h4><span id="伪标记">伪标记</span></h4><p>下面是伪标签标记的原理。首先我们已经标记了数据集的某些部分，使用这些标记数据作为模型的训练集训练模型，这个环节跟之前所讲过的监督学习方法一样。</p><p>通过正常的训练过程使模型的性能表现良好，我们到目前为止所做的一切都是监督学习的一般方法。</p><p>然后无监督学习开始发挥作用。在数据集的标记部分训练结束之后，使用训练好的模型来预测剩余的未标记部分的数据，然后我们采纳这些预测并给这些无标签的数据做标记。</p><p>用我们的神经网络预测的输出标记未标记数据的过程就是伪标记技术的本质。</p><p>在通过伪标记方法标记未标记数据之后，我们在完整数据集上训练模型，包括真实标记的数据以及伪标记的数据。</p><blockquote><p>伪标记允许我们在更大的数据集上进行训练。</p></blockquote><p>否则这些数据可能会花费很多繁琐的人工时间来手动标记。</p><p>我们可以想象，有时获取或生成完全标记数据集的成本太高，或者为所有数据打标签本身的是不可行的。</p><p>通过这个过程，我们可以了解到半监督学习方法是如何利用监督学习下的标记数据以及无监督学习下的未标记数据的，这些数据共同组成了半监督学习的数据来源。</p><p>希望大家现在能够了解半监督学习的内涵，以及如何通过伪标签的技术实施半监督学习。我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> semi-supervised learning </tag>
            
            <tag> 半监督学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无监督学习(unsupervised learning)</title>
      <link href="/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-unsupervised-learning.html"/>
      <url>/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-unsupervised-learning.html</url>
      
        <content type="html"><![CDATA[<h3><span id="机器学习中的无监督学习">机器学习中的无监督学习</span></h3><p>这篇文章讨论<em>无监督学习</em>的概念 。在上篇关于<a href="http://yiyouls.com/2019/02/22/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-supervised-learning/">监督学习</a>的文章中，我们说监督学习使用的是有标记的数据，这是监督学习和无监督学习的显著差别．</p><a id="more"></a><h4><span id="未标记的数据unlabeled-data">未标记的数据(unlabeled data)</span></h4><p>与监督学习相对，当训练集中的数据<em>未被标记</em>时，这时候所进行的就是无监督学习 。</p><blockquote><p>使用未标记的数据进行无监督学习。</p></blockquote><p>在无监督学习的情况下，在训练期间传递给模型的每个数据都只是一个未标记的输入对象(样本)。没有与样本配对的相应标签。</p><p><img src="http://cdn.yiyouls.com/thinking2.gif" alt=""></p><p>嗯…但如果数据没有标注，那么模型是如何学习的？如何评估模型的表现？</p><p>嗯，首先，我们必须面对这样一个事实，即在无监督学习的情况下，由于模型不知道训练数据的真实标签，因此无法对预测准确性做度量。准确性通常不是我们用于分析无监督学习过程的度量标准。</p><p>一般情况下，在无监督学习中模型被赋予一个未标记的数据集，并尝试从数据中学习某种<em>结构(structure)</em>的类型，并从该数据中提取有用的信息或特征。</p><p>它被用来学习如何在没有任何标签的情况下了解这些数据的结构来创建从给定输入到特定输出的映射。</p><h3><span id="无监督学习的例子">无监督学习的例子</span></h3><p>让我们通过一些例子来说明这一点。</p><h4><span id="聚类算法">聚类算法</span></h4><p>无监督学习的最流行应用之一是<em>聚类算法</em>。继续使用我们之前在监督学习的文章中使用过的例子 ，假设我们有特定年龄组<em>男性</em>和<em>女性</em>的<em>身高</em>和<em>体重</em>数据。</p><p>与上次情况不同的是，这次我们没有这些数据的标签，数据集的每个样本只是一个由身高和体重组成的数据对。没有相应的标签能够告诉我们这个人是男性还是女性。</p><p>现在， <a href="https://en.wikipedia.org/wiki/Cluster_analysis" target="_blank" rel="noopener">聚类算法</a>可以分析这些数据，学习它的结构，即便是在没有标记的情况下。通过对结构的学习，模型能够将数据分组。</p><p>我们可以试着对这些数据作一个直观的图示，用ｘ轴表示体重，ｙ轴表示高度，可以得到类似下面的图表．</p><p><img src="http://cdn.yiyouls.com/cluster-2-groups.png" alt=""></p><p>虽然我们不知道这些数据的标签，但是我们可以从图表中看出这里有两个非常明显的聚类，我们推断出这种聚类可能是由男性和女性的个体差别引起的。</p><p>我们还可以推测其中一个聚类的主要成员是女性，另一个聚类的主要成员是男性，因此聚类是无监督学习发挥作用的一个重要领域。让我们再看看另一个例子。</p><h4><span id="自动编码器autoencoder">自动编码器(autoencoder)</span></h4><p>自动编码器使用的也是无监督学习 。</p><p>在一般的话语体系中自动编码器被当作一种人工神经网络，它接收输入，重构该输入并输出结果。</p><p>根据我们所学过的关于神经网络的知识，这个应用听起来很陌生，让我们用一个例子进一步解释。</p><p><img src="http://cdn.yiyouls.com/autoencoder.jpg" alt=""></p><p>我们这里用的示例是由<a href="https://twitter.com/fchollet" target="_blank" rel="noopener">Keras</a>的作者<a href="https://twitter.com/fchollet" target="_blank" rel="noopener">FrançoisChollet</a>在他的<a href="https://blog.keras.io/building-autoencoders-in-keras.html" target="_blank" rel="noopener">博客</a>中写过的，Keras是我们在以往文章中用过很多次的神经网络API。</p><p>假设有一组手写数字的图像，将它们传递给自动编码器。听起来很高大上，但是你要知道自动编码器不过是一个神经网络。</p><p>该神经网络接收该数字的图像，然后对图像<em>进行编码(encode)</em>。最后在网络的末端<em>解码(decode)</em>图像并输出原始图像解码后的重建版。</p><p>这个神经网络的目标是使重建图像尽可能接近原始图像。</p><p><img src="http://cdn.yiyouls.com/mnist-dataset.png" alt=""></p><p>你可能会问一个重建过程中的技术问题：我们怎样才能测量这个自动编码器在重建原始图像时的表现，除了简单的肉眼观察？</p><p>我们可以将自动编码器的损失函数想象为测量图像的重建版本与原始版本的相似程度。重建图像与原始图像越相似，损失越低。</p><p>由于这毕竟是一个人工神经网络，我们仍然会在训练期间使用SGD技术的一些变体，仍然会有最小化损失函数的目标。在训练中对模型进行激励，使重建的图像越来越接近原件。</p><h4><span id="自动编码器的应用">自动编码器的应用</span></h4><p>我们现在对自动编码器的基本概念有了一定了解，那这种人工神经网络能够应用到哪里？对输入进行重建的意义是什么？</p><p>自动编码器的用处之一就是图像去噪。当模型被训练好之后，可以向模型传递噪音过大的相似图像，它将能够提取潜在的有意义的特征并重建一个去除噪音的图像。</p><p>我们现在应该已经能够理解无监督学习的概念，并且了解一些相关应用例如聚类算法和自动编码器。我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 无监督学习 </tag>
            
            <tag> unsupervised learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>监督学习(supervised learning)</title>
      <link href="/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-supervised-learning.html"/>
      <url>/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-supervised-learning.html</url>
      
        <content type="html"><![CDATA[<h3><span id="有监督的机器学习">有监督的机器学习</span></h3><p>这篇文章中讨论有监督学习。到目前为止，在本系列中，每当我们提到模型训练过程或模型经历的学习过程时，我们实际上所指的都是有监督的学习。</p><a id="more"></a><h4><span id="标记数据labeled-data">标记数据(labeled data)</span></h4><p>当我们给训练集中的数据加标签(label)时，我们所做的就是有监督的学习。</p><blockquote><p>标签(label)用于监督或指导学习过程。</p></blockquote><p>我们在训练集，验证集和测试集的文章中解释过，在向模型传递数据的时候，不管是训练数据还是验证数据都是标记过的。这是发生在监督学习中的情况。</p><p>在监督学习中，在训练期间传递给模型的每条数据都是由输入对象（样本）以及相应的标签（输出值）组成的对。</p><p>通过监督学习，模型根据从标记的训练数据中学习知识，建立给定输入到特定输出创建映射。</p><p>例如，假设我们正在训练一个根据爬行动物的图像对不同类型的爬行动物进行分类的模型。训练中我们向模型传递<em>蜥蜴</em>的图像 。</p><p>由于我们进行的是有监督的学习，我们需要为模型提供此图像的标签，也就是说<em>蜥蜴</em>。</p><p>根据<a href="https://yiyouls.com/2019/01/26/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F/">如何训练人工神经网络</a>一文中的介绍，该模型会对图像进行分类输出，然后通过查看该图像的预测值与图像的实际标签之间的差异来确定分类误差．</p><h4><span id="标签以数字形式表示">标签以数字形式表示</span></h4><p>我们需要将标签编码为数字。例如，<em>蜥蜴</em>的标签可以编码为<code>0</code>，而<em>乌龟</em>的标签可以编码为<code>1</code>。</p><p>然后我们将训练集经历完所有epoch，确定它们的损失和误差 。在训练中模型的目标是最大限度地减少损失，因此当我们部署模型并使用它来预测未经训练的数据时，它基于的是训练期间标记过的数据．</p><p>但是，如果我们没有为模型提供相应的标签，那么替代方案是什么？嗯，与监督学习相反，我们可以使用一种称为无监督学习的方法 ，以及另一种称为半监督学习的技术。我们将在以后的文章中介绍这些方面。</p><p>现在，我们通过一些Keras代码，向大家展示怎样向模型传递标记样本。</p><h3><span id="在keras框架下处理标记数据">在Keras框架下处理标记数据</span></h3><p>首先导入相应的库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import keras</span><br><span class="line">from keras import backend as K</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Activation</span><br><span class="line">from keras.layers.core import Dense</span><br><span class="line">from keras.optimizers import Adam</span><br></pre></td></tr></table></figure><p>假设我们使用的是一个简单的<code>Sequential模型</code>，它有两个隐藏的<code>dense</code>层和一个具有两个输出类别的输出层。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(16, input_shape=(2,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(32, activation=&apos;relu&apos;),</span><br><span class="line">    Dense(2, activation=&apos;sigmoid&apos;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>在本系列早期文章中已经介绍了这些所导入的库，模型的体系结构以及我们如何编译模型等内容 。</p><p>我们假设这个模型的任务是根据<em>身高</em>和<em>体重</em>两个特征来为<em>男性</em>和<em>女性</em>分类。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    Adam(lr=0.0001), </span><br><span class="line">    loss=&apos;sparse_categorical_crossentropy&apos;, </span><br><span class="line">    metrics=[&apos;accuracy&apos;]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>在模型编译之后，我们先给大家一些训练数据的示例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 体重, 身高</span><br><span class="line">train_samples = [</span><br><span class="line">    [150, 67], </span><br><span class="line">    [130, 60], </span><br><span class="line">    [200, 65], </span><br><span class="line">    [125, 52], </span><br><span class="line">    [230, 72], </span><br><span class="line">    [181, 70]</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>实际训练数据存储在<code>train_samples</code>变量中。我们用列表来储存这些体重－身高对，每对是一个单独的样本．</p><p>每对中的一个元素是以英镑为单位的体重，第二个元素是以<em>英寸</em>为单位的高度 。</p><p>接下来，我们将标签存储在此<code>train_labels</code>变量中，<code>0</code>代表男性，<code>1</code>代表女性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">＃0：男性</span><br><span class="line">＃1：女性</span><br><span class="line">train_labels = [ 1 ，1 ，0 ，1 ，0 ，0 ]</span><br></pre></td></tr></table></figure><p>每个标签的位置对应于<code>train_samples</code>变量中每个样本的位置。例如，这里的第一个<code>1</code>代表一个女性，是<code>train_samples</code>数组中第一个元素的标签。第二个<code>train_labels</code>元素对应于第二个<code>train_samples</code>元素，以此类推。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.fit(</span><br><span class="line">    x=train_samples, </span><br><span class="line">    y=train_labels,</span><br><span class="line">    batch_size=3,</span><br><span class="line">    epochs=10,</span><br><span class="line">    shuffle=True,</span><br><span class="line">    verbose=2</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>我们通过调用<code>model.fit()</code>来训练模型，这在之前的文章中讲过，这里指定的第一个参数<code>x</code>是<code>train_samples</code> 变量，而第二个参数<code>y</code>是相应的<code>train_labels</code>。</p><p>希望您现在能够理解监督学习是什么以及如何做监督学习。在后面的文章中，我们将这个方法与其他学习方法进行对比。下篇文章见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> supervised learning </tag>
            
            <tag> 监督学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络是如何进行预测(prediction)的?</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B-prediction-%E7%9A%84.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B-prediction-%E7%9A%84.html</url>
      
        <content type="html"><![CDATA[<h4><span id="用神经网络做预测">用神经网络做预测</span></h4><p>在这篇文章中，我们将讨论使用人工神经网络进行预测的含义，以及如何使用Keras框架写出模型预测的代码。</p><a id="more"></a><p>在 <a href="https://yiyouls.com/2019/01/26/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F/">之前的文章中</a>，我们讨论了如何训练神经网络。在此训练完成后，如果我们对模型在训练数据和验证数据中的指标感到满意，那么下一步就是让模型预测测试集中的数据</p><p>回想一下<a href="https://yiyouls.com/2019/01/27/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86-training-set-%EF%BC%8C%E9%AA%8C%E8%AF%81%E9%9B%86-validation-set-%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95%E9%9B%86-test-set/">关于训练集，测试集和验证集的文章</a>，不同于训练集和验证集，当我们将测试数据传递给模型时，相应的标签<em>不会</em>被传递。因此，模型根本不知道测试集的标签。</p><h4><span id="传递没有标签的样本">传递没有标签的样本</span></h4><p>关于使用模型作预测，大概来讲是将未标记的测试数据传递给模型，并让模型对测试数据的样本标签做预测。这些预测基于模型在训练过程中学到的知识。</p><blockquote><p>预测是基于模型在训练期间学到的知识。</p></blockquote><p>例如，假设我们训练了一个模型，这个模型根据狗的图像对不同品种的狗进行分类。对于每个样本图像，模型能够输出最有可能的分类结果。</p><p>现在假设测试集包含模型以前没有见过的狗的图像。我们将这些样本传递给模型，并要求它预测每个图像的输出。要记得，模型是没有办法访问这些图像的标签的。</p><p>这个过程会提供给我们模型对它之前没有见过的数据的执行情况，我们需要分析它的预测与数据的真实标签的匹配程度。</p><p>这个过程也有助于我们了解模型到底有没有学到知识。例如，假设我们仅在大型犬的图像上训练模型，但我们的测试集中有一些小型犬的图像。当我们将一只小狗传给我们的模型时，它可能不会很好地预测狗是什么品种，因为这样的模型通常不适合小型犬的预测。</p><p>这意味着我们需要确保培训集和验证集能够代表我们希望模型预测的实际数据。</p><h4><span id="在现实中部署模型工业化">在现实中部署模型（工业化）</span></h4><p>除了对测试数据进行运行预测之外，我们还可以让模型在部署后进行实用来预测现实世界中的数据。</p><p>例如，如果我们将这种神经网络应用于互联网世界，每个人都可以上传并访问他的的狗的照片，得到关于他们的狗的品种的信息．</p><p>这些图像不是我们的训练集，验证或测试集中包含的图像，它们是在显示世界中需要我们进行预测的图像。</p><p>现在让我们看看如何使用Keras框架进行这些预测。</p><h3><span id="使用keras框架进行模型预测">使用Keras框架进行模型预测</span></h3><p>假设有以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict(</span><br><span class="line">    scaled_test_samples, </span><br><span class="line">    batch_size=10, </span><br><span class="line">    verbose=0</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这里的第一项是我们称之为<code>predictions</code>的变量。假设我们已经设计并训练好了我们的模型。我们在这个例子中的模型是<code>model</code>这个对象。我们将<code>predictions</code>用<code>model.predict()</code>赋值。</p><p>这个<code>predict()</code>函数是实际上要做预测的函数。对于<code>predict()</code>函数，我们传递了名为<code>scaled_test_samples</code>的变量，用来保存测试数据。</p><p><code>batch_size</code>在这任意设置为<code>10</code>。然后设置<code>verbose=0</code>，这是我们在运行这些预测时打印到屏幕上的数量，<code>0</code>表示不显示任何内容。</p><p>我们在这里使用的模型样本在我们以前的文章中使用过。因此在这里不详细介绍实际模型，但如果您有兴趣构建一个同样的模型并运行相同的预测，请参考Keras系列中关于预处理数据和创建混淆矩阵(confusion matrix)的文章</p><p>目前，我们只是展示了如何在Keras框架下进行预测的概念。</p><p>我们运行预测程序，会得到这样的输出。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for p in predictions:</span><br><span class="line">    print(p)</span><br><span class="line"></span><br><span class="line">[ 0.7410683  0.2589317]</span><br><span class="line">[ 0.14958295  0.85041702]</span><br><span class="line">...</span><br><span class="line">[ 0.87152088  0.12847912]</span><br><span class="line">[ 0.04943148  0.95056852]</span><br></pre></td></tr></table></figure><p>在这个例子中，这个模型有两个输出类别，我们打印测试集中每个样本的每个预测，它存储在<code>predictions</code>变量中。</p><p>观察这个输出列表，一共有两列，代表两个输出类别，显示每个类别的概率。它们都是实际的预测结果。这两个类别我们不妨简称为类别<code>0</code>和类别<code>1</code>.</p><p>我们再仔细看一下，对于测试集中的第一个样本，模型分配<code>74%</code>的可能性给类别<code>0</code>,只有<code>26%</code>的概率分配给类别<code>1</code>。</p><p>第二个样本向我们展示了模型分配<code>85%</code>的概率给类别<code>1</code>和<code>15%</code>概率给类别<code>0</code>，每个测试样本的输出都可以这样解读。</p><p>这就是关于神经网络在Keras框架下做预测的方法，希望你能够对神经网络如何做预测有了一定了解。下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> fine-tune </tag>
            
            <tag> 微调 </tag>
            
            <tag> transfer learning </tag>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习中的数据增强(data augmentation)技术</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-data-augmentation-%E6%8A%80%E6%9C%AF.html"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-data-augmentation-%E6%8A%80%E6%9C%AF.html</url>
      
        <content type="html"><![CDATA[<p>在这篇文章中，我们会<em>数据增强</em>技术以及它的实现方式。</p><p>当我们通过修改现有数据的方式创建新数据时，我们称之为数据增强。我们实际上是通过对训练集中的数据进行合理修改来创建新的增强数据。</p><a id="more"></a><blockquote><p>数据增强是通过修改现有数据的方式创建新数据。</p></blockquote><p>例如，我们可以通过水平或垂直翻转图像来增强图像数据。这包括图像的旋转，放大或缩小，裁剪，甚至改变图像的颜色。所有这些都是常见的数据增强技术。</p><ul><li>水平翻转</li><li>垂直翻转</li><li>轴心旋转</li><li>放大</li><li>缩小</li><li>裁剪</li><li>颜色变化</li></ul><p>我们为什么要这样做呢？使用数据增强技术的意义在哪里？</p><h3><span id="为什么要使用数据增强">为什么要使用数据增强？</span></h3><p>原因或许很简单，我们可能只是想要或者试验需要我们在训练集中添加更多数据。例如，在一些情况下我们的训练集中样本数量偏少，并且很难获得更多新样本。这种情况下，我们可以使用数据增强从现有数据集创建新数据，以创建更多样本。</p><h4><span id="减少过度拟合">减少过度拟合</span></h4><p>此外，我们也可以使用数据增强来减少过度拟合。大家可以回顾一下我们在之前文章中提到了<a href="https://blog.yiyouls.com/2019/01/27/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88-overfitting/" target="_blank" rel="noopener">过度拟合的概念</a> 。</p><p>如果我们的模型过度拟合，可以通过向训练集添加更多数据这种技术来减少过度拟合。就像我们前面提到的原因，如果我们无法搜集更多的数据，我们可以使用数据增强轻松创建更多数据。</p><p>此外，关于过度拟合的另外一点，假设我们有一个全是狗的图像的数据集，但这个数据集的特点是大多数狗面向右边。</p><p>如果对这些图像进行模型训练，那么认为模型会认为只有这些面向右面的狗的图像才是合理的。当我们在真实世界中运用这个模型或者用它来预测测试图像时，那些面向左边的狗很可能不会被正确分类。</p><p>在这个背景下，可以通过合理修改面向右侧的狗的图像来增加面向左侧的狗的图像，我们可以通过水平翻转原始图像来生成新图像。</p><p>但是，一些特定的数据增强技术可能不适合在给定的数据集上使用。依然是狗的例子，如果说水平翻转狗的图像是有道理的，然而，通过垂直翻转来修改狗的图像不一定是合理的。因为在真实世界中，我们不太可能看到这样将头部倒置的狗的图像。</p><p>希望你现在能够了解数据增强是什么以及使用它的意义在哪里。如果想要知道如何使用Keras在代码中实现数据增强，精确关注我们的Keras系列教程。在该系列中，我们将展示如何通过旋转图像，改变宽度和高度，缩放，改变颜色以及水平翻转图像，从单个狗的原始图像制作出１０个增强图像。</p><p>我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> data augmentation </tag>
            
            <tag> 数据增强 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络如何进行微调(fine-tuning)</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83-fine-tuning.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83-fine-tuning.html</url>
      
        <content type="html"><![CDATA[<h4><span id="微调神经网络">微调神经网络</span></h4><p>这篇文章向大家解释什么是微调，以及在建立和训练模型的时候如何利用微调技术．</p><a id="more"></a><h4><span id="迁移学习transfer-learning与微调">迁移学习(transfer learning)与微调</span></h4><p>微调这个概念是和迁移学习联系在一起的．当我们使用从解决一个问题中获得的知识并将其应用于新的但相关的问题时，这就是所谓的迁移学习。</p><blockquote><p>迁移学习是我们利用从解决过的问题中获取的知识，将其应用于新的但相关的问题</p></blockquote><p>例如，我们从学习识别汽车的神经网络中获取的知识，可以应用于卡车的识别问题．</p><p>微调是迁移学习的一种手段，可以帮助我们利用已有的模型．具体来说，微调是一个过程，它利用已经训练好的模型，这个模型针对的是一个相关任务，然后调整模型使它适合新任务．</p><h5><span id="为什么要使用微调技术">为什么要使用微调技术</span></h5><p>假设原始任务类似于新任务，使用已经设计和训练的人工神经网络允许我们利用模型已经学习的内容而无需从头开始。从头开始构建模型时，我们通常必须通过反复试验尝试多种方法。</p><p>例如，我们必须选择合适的层数，层的类型，层的放置顺序，每层中包含的节点数，决定要使用多少正则化，将学习率设为多少等等。</p><ul><li>层数</li><li>层的类型</li><li>层的顺序</li><li>每层中的节点数</li><li>正则化</li><li>学习率</li></ul><p>根据训练数据设计和验证模型本身就是一项艰巨的任务。</p><p>这使得微调方法如此具有吸引力。如果我们能够找到已经能够出色完成相关任务的训练模型，这个任务至少在某种程度上与我们的任务类似，那么我们就可以对已经学到的所有内容加以利用并将其应用到我们的特定任务上。</p><p>当然，如果两个任务不同，那么模型已经学习的某些信息可能不适用于新任务，或者可能存在需要从新数据中学习的新信息。</p><p>例如，一个在小汽车数据上训练得到的模型，并没有见到过卡车的数据，模型在这种情况下必须要学习到一些新的特征。但是，卡车数据的某些特征也是存在于小汽车数据中的。</p><p>在小汽车数据上训练过的模型已经可以理解汽车的边，形状和纹理，认识前照灯，门把手，挡风玻璃，轮胎等部件。这些学到的特征是可以在新的模型中加以利用的。</p><p>这个方法听起来还是蛮有吸引力的，但我们如何在技术上实现这一点呢？</p><h3><span id="如何微调">如何微调</span></h3><p>回到我们刚刚提到的例子，如果我们有一个已经训练过的能够识别小汽车的模型，希望通过微调这个模型以识别卡车，我们可以先导入用于识别汽车的原始模型。</p><p>为简单起见，假设我们删除了此模型的最后一层。最后一层已经能够做到正确分类图像是否是汽车。之后用一个分类图像是否是卡车的模型来替换输出层。</p><p>在某些问题中，我们需要删除的可能不仅仅是最后一层，需要添加的也不仅仅是最后一层。这取决于模型任务的相似程度。</p><p>模型末端的层能够学习到特定任务所特有的一些特征，模型开始处的图层通常只能学习到更多一般的特征，如边，形状和纹理。</p><p>在我们修改了现有模型的结构之后，我们需要冻结新模型中这些来自原始模型的层。</p><h4><span id="冻结权重">冻结权重</span></h4><p>通过 <em>冻结(freezing)</em>，在新任务的新数据上训练模型，被冻结的这些层的权重就不会被更新。我们希望这些权重与原始任务训练后的权重保持不变。我们只需要更新或修改新层中的权重。</p><p>之后就是在新数据上训练模型。要记得在训练过程中，从原始模型中保留的所有层的权重将保持不变，只有新层中的权重才会更新。</p><p>到目前为止我们已经对迁移学习中的微调有了全面的认识，明白了微调方法能够节省我们很多工作．想要了解如何在Keras框架下设计一个微调模型，训练并使用这个模型，敬请期待我们的Keras系列教程．我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> fine-tune </tag>
            
            <tag> 微调 </tag>
            
            <tag> transfer learning </tag>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络中的批尺寸(batch size)详解</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%89%B9%E5%B0%BA%E5%AF%B8-batch-size.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%89%B9%E5%B0%BA%E5%AF%B8-batch-size.html</url>
      
        <content type="html"><![CDATA[<h4><span id="人工神经网络中的批尺寸">人工神经网络中的批尺寸</span></h4><p>这篇文章向大家介绍在训练人工神经网络的过程中指定批尺寸的意思是什么，以及如何在Keras中为模型定义一个批尺寸．</p><a id="more"></a><p>在<a href="https://yiyouls.com/2019/01/27/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0-learn-%E7%9A%84/">之前关于神经网络如何学习的文章</a>中，我们已经了解了在我们训练模型的时候，我们需要指定一个批尺寸，我们这篇文章将要详细介绍这一点．</p><h4><span id="什么是批尺寸">什么是批尺寸</span></h4><p>简单来说，批尺寸的意思是每次训练我们给模型传递多少数据，一个批(batch)也被称作一个mini-batch.</p><blockquote><p>批尺寸指的是一次性向网络传递多少样本</p></blockquote><p>我们知道一个epoch指的是把训练集所有数据在网络中传递一遍，因此批尺寸和epoch不是一个东西．我们通过一个例子来比较它们之间的关系．</p><h5><span id="一个epoch中可以有很多批">一个epoch中可以有很多批</span></h5><p>假设我们有1000张犬类照片，希望通过一个神经网络区分出它们的不同种类，如果我们把批尺寸定义为<code>10</code>，那么一组10张的图片会被一起传递给网络，每十张作为一个批次．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个epoch中的批数＝训练集大小／批尺寸</span><br></pre></td></tr></table></figure><p>我们现在明白了批尺寸的概念，但是分批的意义是什么？为什么不把数据中的所有元素一个接一个地传递给网络呢？为什么要把数据分成不同的批次？</p><h5><span id="为什么要分批">为什么要分批</span></h5><p>在目前的计算能力下，计算机能够一次处理很多个数据．一般来讲，批尺寸越大，模型训练中就能够更快地完成一次epoch.</p><p>但是这种方式也有确定，因为即使机器能够处理一些尺寸很大的批，当我们把批尺寸设的过大的时候，会降低模型的质量，这会导致模型的泛化能力降低．</p><p>所以，批尺寸是另外一个我们需要考虑的超参数，这个超参的调整不仅仅与我们的模型要求有关，也与我们所能够利用的计算资源有关．</p><p>举例来说，如果我们给批尺寸指定了一个相对较大的数值，例如<code>100</code>，这时机器可能没有能力通过并行的方式一次性处理这１００张图片，这个时候我们就需要把批尺寸降低一些．</p><p>到目前为止相信大家对批尺寸已经有了大致的了解，我们来看一看如何在Keras框架中指定这个参数．</p><h4><span id="在keras中用代码指定批尺寸">在Keras中用代码指定批尺寸</span></h4><p>依然使用我们在之前文章中使用过的顺序模型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(16, input_shape=(1,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(32, activation=&apos;relu&apos;, kernel_regularizer=regularizers.l2(0.01)),</span><br><span class="line">    Dense(2, activation=&apos;sigmoid&apos;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p> 我们这里重点关注在哪里调用<code>model.fit()</code>方法，这是我们在训练模型时候用到的函数，我们在<a href="https://blog.yiyouls.com/2019/01/27/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0-learn-%E7%9A%84/" target="_blank" rel="noopener">之前介绍神经网络如何学习的文章</a>中使用过它．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.fit(</span><br><span class="line">    scaled_train_samples, </span><br><span class="line">    train_labels, </span><br><span class="line">    validation_data=valid_set, </span><br><span class="line">    batch_size=10,</span><br><span class="line">    epochs=20, </span><br><span class="line">    shuffle=True, </span><br><span class="line">    verbose=2</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>在这里<code>fit()</code>函数接受一个<code>batch_size</code>的参数，我们就是在这里指定训练的批尺寸的．在这个例子里我们给他随意指定了一个值<code>10</code>．</p><p>这样我们在训练中每次向模型传递１０个样本，在一个epoch结束时把所有的样本都传递一遍，在下一关epoch中再次循环一遍．</p><p>希望你现在对批尺寸这个概念有了一个清晰的认识，并且学会在Keras中指定批尺寸．我们下篇文章见．</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 批尺寸 </tag>
            
            <tag> batch size </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络中的学习率(learning rate)问题</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%87-learning-rate.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%87-learning-rate.html</url>
      
        <content type="html"><![CDATA[<h4><span id="学习率与神经网络">学习率与神经网络</span></h4><p>这篇文章介绍学习率的问题，向大家解释学习率在模型训练中的作用．</p><a id="more"></a><p>在<a href="https://yiyouls.com/2019/01/27/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0-learn-%E7%9A%84/">之前的文章</a>中我们向大家介绍过神经网络是怎样学习的，＂学习＂一词具体指的是什么．在那里我们第一次提到学习率的问题，在模型学习过程中我们要给梯度值乘以学习率，我们现在来具体了解一下这个问题．</p><h4><span id="什么是学习率">什么是学习率</span></h4><p>模型训练的目标是通过SGD的方法最小化训练数据预测输出与实际输出的损失．要完成这一目标需要几个步骤．</p><p>训练一开始我们先给模型随机赋予一些初始权重，之后在每轮训练中我们更新权重，一步步直至接近于最小化损失．</p><p>我们在这里所需要的步数是由我们指定的学习率决定的，从概念上，我们可以将模型的学习率理解为步长．</p><p>在进一步探讨之前，我们再一次回顾之前学过的内容．在模型训练过程中，通过损失函数计算输入数据的损失，之后计算模型每个权重下损失函数的梯度．</p><p>我们在获得这些梯度值之后，我们开始指定一个学习率，将梯度与学习率相乘．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">梯度＊学习率</span><br></pre></td></tr></table></figure><p>学习率的值很小，通常介于0.01-0.0001之间．实际值的选择范围很宽，我们需要明白的是，当梯度值乘以这个学习率之后所得的值就会变得很小．</p><h4><span id="更新网络的权重">更新网络的权重</span></h4><p>我们将每个梯度值乘以学习率得到它们的乘积，将原来的权重减去这个乘积得到新权重，以此来更新权重．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">新权重＝旧权重－（学习率＊梯度）</span><br></pre></td></tr></table></figure><p>我们通过分解网络在每个连接处的旧权重，赋予它们新值，来更新权重．</p><p>学习率的选择是需要进行验证的，它也是一个超参数(hyperparameters)，我们需要通过测试和调整来选择最为恰当的值，而不是从一开始就知道对于特定模型最合适的学习率．学习率的初始值最好是在0.01-0.0001之间．</p><p>如果我们把学习率定在这个范围内较大的位置，就可能会有超调(overshooting)的风险，由于向最小化损失函数反向移动的步长过大，导致跨过最小值的点，这样就无法真正最小化损失函数．</p><p>所以，到底是选择较大的学习率还是较小的学习率，这是一个人工智能研究员根据经验做出的取舍．</p><p>至此，我们已经了解了学习率这个概念，以及它是如何在神经网络训练中起作用的．我们接下来看一看如何在keras框架下指定学习率．</p><h4><span id="在keras中用代码表示学习率">在Keras中用代码表示学习率</span></h4><p>我们仍然使用之前讲过的模型．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(16, input_shape=(1,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(32, activation=&apos;relu&apos;, kernel_regularizer=regularizers.l2(0.01)),</span><br><span class="line">    Dense(2, activation=&apos;sigmoid&apos;)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    Adam(lr=0.0001), </span><br><span class="line">    loss=&apos;sparse_categorical_crossentropy&apos;, </span><br><span class="line">    metrics=[&apos;accuracy&apos;]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>通过上面的代码我们编译了一个模型，并且指定了一个叫做<code>Adam</code>的优化器．</p><p>对于这个优化器，我们可以通过指定<code>lr</code>参数给他传递一个学习率，这里所指定的学习率是<code>0.0001</code>.</p><p>不过，<code>lr</code>参数是可以缺省的．如果不指定这个参数，keras会给它分配一个默认的值，对于不同的优化器，有不同的学习率默认参数，至于这个默认值具体是什么，请参照<a href="https://keras.io/optimizers/" target="_blank" rel="noopener">Keras官方文档</a>．</p><p>给优化器指定学习率还有另外一个方式，在模型编译之后，我们通过给<code>model.optimizer.lr</code>赋值的方式指定学习率．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.optimizer.lr = 0.01</span><br></pre></td></tr></table></figure><p> 在这里将学习率设定为<code>0.01</code>．当我们在终端打印出学习率的值，可以看到它已经由默认值<code>.0001</code>更改为<code>.01</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; model.optimizer.lr</span><br><span class="line">0.01</span><br></pre></td></tr></table></figure><p>以上就是在模型中给优化器指定学习率的两种方式．</p><p>到目前我们已经对什么是学习率有了一个了解，明白它是怎么在模型训练中起作用的，以及为什么需要通过测验和调试来寻址模型的最佳学习率，并且，我们应该已经能够在keras中为优化器指定一个学习率了．我们下篇文章再见．</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 学习率 </tag>
            
            <tag> learning rate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络中的正则化(regularization)</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96-regularization.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96-regularization.html</url>
      
        <content type="html"><![CDATA[<p>这篇文章探讨什么是正则化，以及在神经网络中加入正则化的原因．</p><p>在<a href="https://yiyouls.com/2019/01/27/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88-overfitting/">之前文章</a>中我们讲过过度拟合的问题，简单介绍过dropout的技术，它是正则化的一种．但是我们并没有详细说什么是正则化，这篇文章将会补充这一部分内容．</p><a id="more"></a><p>一般来讲，正则化通过惩罚过度复杂的模型来帮助模型减少过度拟合，弱化模型的变异．因为模型越复杂可能会使得模型泛化能力变弱，即使模型能够很好地契合数据．</p><blockquote><p>正则化通过惩罚过度复杂的模型来帮助模型减少过度拟合，弱化模型的变异</p></blockquote><p>所以，如果我们在模型中加入正则化技术，我们会不可避免地牺牲一些模型对于数据的契合能力来获取模型更好的泛化能力，这样模型就能对从未见过的新数据有更好的宽容度．</p><p>如何给模型加入正则化呢，我们只需在损失函数中添加一个惩罚项，去减弱那些过多的权重．我们待会会详细介绍这一点．</p><h4><span id="l2正则化">L2正则化</span></h4><p>最经常使用的正则化计算是L2正则化，那L2正则化是怎样在损失函数中添加惩罚项的呢．</p><h4><span id="l2正则化表达式">L2正则化表达式</span></h4><p>在L2正则化中我们给损失函数添加了权重矩阵的范数平方(squared norms)和，表达式为：</p><p>$\sum ^{n}_{j=1}||w^{|j|}||^2$,</p><p>并乘以一个数值很小的常量</p><p>$\frac {\lambda}{2m}$.</p><h5><span id="范数的非负性">范数的非负性</span></h5><p>如果你大致了解范数这一概念，你就能理解范数不过是给向量空间中的每个向量赋予一个严格为正的长度或大小的函数．我们这里所处理的模型空间依赖于权重矩阵的大小．</p><p>我们这里不过多考虑范数的线性代数分析，还是回到正则化这条主线上来．范数是线性代数中的一个基本概念，如果你需要对它作进一步了解，你可以在网络上找到很多介绍．</p><p>我们在这里只需要了解，每一个权重矩阵的范数都是一个非负数．</p><p>假设$v$是向量空间中的一个向量，$v$的范数用$||v||$来标记，注意，</p><p>$||v||\ge0$,</p><h5><span id="给损失函数加入正则化">给损失函数加入正则化</span></h5><p>L2正则化的表达式如下</p><p>$loss+(\sum ^{n}_{j=1}||w^{|j|}||^2)\frac {\lambda}{2m}$.</p><p>下面的表格是表达式中所有变量的定义</p><div class="table-container"><table><thead><tr><th>变量</th><th>定义</th></tr></thead><tbody><tr><td>$n$</td><td>神经网络的层数</td></tr><tr><td>$w$j</td><td>第$j$层的权重矩阵</td></tr><tr><td>$m$</td><td>输入数据的个数</td></tr><tr><td>$\lambda$</td><td>正则化参数</td></tr></tbody></table></div><p>$\lambda$是正则化参数，它是我们在建立模型中另一个需要考虑的超参，我们通过选择超参，测试并调整超参以适应不同模型的需求．</p><p>总结一下，目前我们了解了正则化的目的是弱化模型中相对较大的权重，而这是通过对损失函数添加惩罚项实现的．那么到底为什么正则化的方法可以帮助我们优化模型呢？</p><h4><span id="正则化的影响">正则化的影响</span></h4><p>以Ｌ2正则化为例，如果我们将超参数$\lambda$定得比较大，就会激励模型参数向０靠拢，因为SGD的目标是最小化<a href="https://blog.yiyouls.com/2019/01/27/%E6%B7%B1%E5%85%A5%E8%AE%A4%E8%AF%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-function/" target="_blank" rel="noopener">损失函数</a>，要记得我们给最初的损失函数加了权重矩阵的范数平方和</p><p>$\sum ^{n}_{j=1}||w^{|j|}||^2$,</p><p>并乘以一个数值很小的常量</p><p>$\frac {\lambda}{2m}$.</p><p>假如$\lambda$的值比较大，那么$\frac {\lambda}{2m}$也会保持一个较大值，将这个值乘以范数平方和，那么所得的乘积也可能会相对较大，这取决于权重值的大小．这以为着模型会被激励着使权重值减小，来保证整个函数值保持在相对较小，以此最小化损失．</p><p>这样的化，这种正则化可能会导致权重趋向于０，甚至会使的模型的某些层不再发挥作用，这样就使得模型不再那么复杂，模型的简化能够减少过低拟合，减少模型变异．</p><p>希望大家到这里能够对正则化有比较清晰的认识，了解正则化起作用的方式，以及对L2正则化表达式有所熟悉．之后我们会对学习率(learning rate)做一个介绍，我们下次再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 正则化 </tag>
            
            <tag> L2正则化 </tag>
            
            <tag> 范数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是神经网络模型欠拟合(underfitting)?</title>
      <link href="/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%AC%A0%E6%8B%9F%E5%90%88-underfitting.html"/>
      <url>/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%AC%A0%E6%8B%9F%E5%90%88-underfitting.html</url>
      
        <content type="html"><![CDATA[<h3><span id="神经网络中的欠拟合underfitting">神经网络中的欠拟合(underfitting)</span></h3><p>在这篇文章中，我们将讨论当模型被认为欠拟合意味着什么，并且介绍一些可以用来减少欠拟合的技术。</p><p>在之前的文章中，我们将过度拟合定义为我们的模型能够对训练数据进行有效预测，但是准确预测以前从未见过的数据。</p><p>欠拟合与之恰恰相反。欠拟合的模型甚至无法对它所训练的数据进行正确分类，更不用说它以前没见过的数据了。</p><a id="more"></a><blockquote><p>当一个模型无法对其训练的数据进行正确分类时，该模型被认为是欠拟合(underfitting)的。</p></blockquote><p>我们可以通过模型的度量参数来判断，如果模型的训练的准确度低或训练的损失很高，模型就是欠拟合的。</p><p>如果模型无法对其经过训练的数据进行分类，则可能无法很好地预测之前未曾见过的数据。</p><h3><span id="减少欠拟合">减少欠拟合</span></h3><p>现在我们知道什么样的模型是欠拟合的，我们怎样才能减少这种欠拟合呢？</p><h4><span id="增加模型的复杂度">增加模型的复杂度</span></h4><p>我们可以做的第一件事是增加模型的复杂度。这与我们为减少过度拟合所采用的技术完全相反。如果我们的数据太复杂，但我们有一个相对简单的模型，那么该模型的复杂度可能就不够高，无法准确地对复杂数据进行分类或预测。</p><p>我们可以通过以下方式增加模型的复杂度：</p><ul><li>增加模型的层数。</li><li>增加每层神经元的数量。</li><li>更改层的类型和位置。</li></ul><h4><span id="为输入样本添加更多特征features">为输入样本添加更多特征(features)</span></h4><p>减少欠拟合的另一种技术是在我们的训练集中为输入样本添加更多特征。这些添加的特征可以帮助模型更好地对数据进行分类。</p><p>例如，假设我们有一个模型试图根据某股票的最后三个收盘价来预测股票的价格。这个时候输入一共有三个特征：</p><ul><li>第1天收盘</li><li>第2天收盘</li><li>第3天收盘</li></ul><p>如果我们为这些数据添加了额外的特征 ，例如，这些天的开盘价或当天的库存量，那么这可能有助于我们的模型更多地了解数据并提高其准确性。</p><h4><span id="减少dropout">减少dropout</span></h4><p>我们这里讨论的最后一个方法是减少dropout。同样，这与我们在前一篇文章中减少过度拟合的技术完全相反 。</p><p>使用dropout时，我们可以指定要删除的节点的百分比。因此，如果我们使用<code>50%</code>的dropout率，发现模型欠拟合，那么我们可以通过将比率降低到低于<code>50</code>的值来减少dropout，再次训练并观察相关度量指标。</p><p>这些节点仅在训练时dropout，而不是在验证期间。因此，如果我们观察到模型更适合我们的验证数据而不是训练数据，这是说明dropout数量的减少会提高模型拟合程度的一个重要指标．</p><p>希望你现在能够理解欠拟合的概念，它为什么会发生，如何减少欠拟合。在接下来的文章中，我们将着眼于正则化的神经网络。下次见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 欠拟合 </tag>
            
            <tag> underfitting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是神经网络模型过度拟合(overfitting)?</title>
      <link href="/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88-overfitting.html"/>
      <url>/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88-overfitting.html</url>
      
        <content type="html"><![CDATA[<p>神经网络中的过度拟合(overfitting)</p><p>这篇文章我们介绍过度拟合的含义，以及一些减少过度拟合的技术．</p><p>上篇文章中我们在讨论验证集的时候提到了过度拟合的概念，我们现在具体讨论一下它．</p><p>当模型能够对训练集中包含的数据进行正确分类或预测，但是在对未经过训练的数据进行分类时效果不佳，就会发生过度拟合。这个时候该模型过度学习了训练集中的数据。</p><a id="more"></a><h3><span id="如何检查模型是否过度拟合">如何检查模型是否过度拟合</span></h3><p>我们根据模型训练过程中训练数据和验证数据的相关指标来判断模型是否过度拟合．当我们在训练中指定验证集的时候，我们同时得到模型验证的准确度和损失，以及模型训练的准确度和损失．</p><p>如果验证指标比训练指标差得多，则表明我们的模型过度拟合。</p><p>如果在训练期间，模型的指标是好的，但是当我们使用模型来预测测试数据时，它不能准确地对测试集中的数据进行分类，我们也可以得知我们的模型过度拟合。</p><p>过度拟合的概念可以归结为模型无法很好地进行泛化。它已经非常好地学习了训练集的特征，但是如果我们给模型任何稍微偏离训练期间所使用数据的新数据，它就无法对特征进行推广，不能准确预测输出。</p><h3><span id="减少过度拟合">减少过度拟合</span></h3><p>过度拟合是一个非常常见的问题。我们怎样才能减少过度拟合呢？我们来看看一些技巧。</p><h4><span id="向训练集添加更多数据">向训练集添加更多数据</span></h4><p>最简单的方法就是添加更多数据。我们可以训练模型的数据越多，从训练集中学到的知识就越多。此外，随着数据的增加，我们希望增加数据集的多样性。</p><p>例如，如果我们训练模型来分类图像是狗或猫的图像，但只给模型一些大型犬的图像，如拉布拉多，金毛猎犬等，那么在实践中如果它看到一只博美犬，它可能不太能认出这是一条狗。</p><p>如果我们向该模型添加更多以包含更多品种狗的数据，那么我们的训练数据将变得更加多样化，这样模型就不太可能过度拟合了。</p><h4><span id="数据增强">数据增强</span></h4><p>减少模型过度拟合的另一个技巧是使用数据增强(data augmentation)，这是通过合理修改训练集中的数据来产生更多数据的过程。例如，对于图像数据，我们可以通过以下方式对数据进行修改：</p><ul><li>裁剪</li><li>旋转</li><li>翻转</li><li>缩放</li></ul><p>我们将在后面的文章中详细介绍数据增强的概念 。</p><p>数据增强的理念是允许我们向训练集添加更多数据，这些数据与我们已有的数据类似，它们并不完全相同，是某种程度上进行的合理的修改。</p><p>例如，如果我们的大多数狗图像都是面向左侧的狗，那么添加翻转图像的增强数据将是一个合理的修改，这样我们的训练集也会有面向右侧的狗了。</p><h4><span id="降低模型的复杂度">降低模型的复杂度</span></h4><p>我们可以采取的其他措施来减少过度拟合，比如降低模型的复杂度。我们可以通过简单的更改来降低复杂性，例如从模型中删除一些层，或减少层中神经元的数量。这可能有助于提高模型对以前从未见过的数据的泛化能力。</p><h4><span id="dropout">Dropout</span></h4><p>我们这里最后再讲一个减少过度拟合的方法－dropout 。这个方法背后的理念是，如果我们给模型添加dropout，它将在训练期间随机忽略给定层中的某些节点子集，即，它从层中<em>删除</em>一些节点。这些被dropout的节点将不参与数据的预测．</p><p>这个技术同样可以提高模型的泛化能力。dropout是一种正则化技术(regularization technique)，我们会在以后的文章中完整介绍这个概念， 你也将理解为什么dropout能够满足我们的需要。</p><p>希望你现在能够理解过度拟合的概念，明白它为什么会发生，以及如何去减少它。在接下来的文章中，我们将探讨欠拟合的概念。下次再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 过度拟合 </tag>
            
            <tag> overfitting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何理解数据集中的训练集(training set)，验证集(validation set)以及测试集(test set)?</title>
      <link href="/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86-training-set-%EF%BC%8C%E9%AA%8C%E8%AF%81%E9%9B%86-validation-set-%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95%E9%9B%86-test-set.html"/>
      <url>/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86-training-set-%EF%BC%8C%E9%AA%8C%E8%AF%81%E9%9B%86-validation-set-%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95%E9%9B%86-test-set.html</url>
      
        <content type="html"><![CDATA[<p>这篇文章带大家了解神经网络训练和测试中用到的不同种类的数据集．</p><p>为了训练和测试神经网络，我们需要将数据集划分为三个独立的数据集，这些数据集将包含以下内容：</p><ul><li>训练集 training set</li><li>验证集 validation set</li><li>测试集 test set</li></ul><a id="more"></a><p> 首先说说训练集.</p><h4><span id="训练集">训练集</span></h4><p>顾名思义，训练集是用来训练模型的数据集合，通过每一次epoch，模型对训练集中的数据一遍又一遍反复训练，不断学习数据的特征．</p><p>这么做的目的是，当模型遇到从没有见到过的新数据时，能够对它做出准确的预测．那么什么是验证集呢？</p><h4><span id="验证集">验证集</span></h4><p>验证集是一组与训练集分开的数据，用于在训练期间验证我们的模型。此验证过程有助于提供可帮助我们调整超参数的信息。</p><p>在每个epoch中，模型不只是在训练集中的数据上进行训练，同时也在验证集中的数据上进行验证。</p><p>我们之前在关于模型训练的文章中讲过，在训练过程中，模型将对培训集中每个输入的输出进行分类。在进行该分类之后，计算出损失，并且调整模型中的权重。然后，在下个epoch期间，模型再次对相同的输入进行分类。</p><p>而现在我们需要知道，在训练期间，模型也会对验证集中的每个输入进行分类。这种分类仅基于模型在训练集中训练得到的关于数据的知识。通过验证数据计算的损失，但模型中的权重不会因此更新。</p><p>请记住，验证集中的数据与训练集中的数据是分开的。因此，当模型验证时的数据并不在之前的训练中出现．</p><p>验证集存在的一个主要原因是确保我们的模型不会过度拟合(overfitting)训练集中的数据。我们会在之后详细讨论过度拟合和欠拟合(underfitting)。现在大家只需要知道过度拟合是指模型非常善于对训练集中的数据进行分类，但却无法对未经过训练的数据进行概括和精确分类。</p><p>如果我们在训练过程中同时使用验证集来验证模型，并且发现模型对验证集的预测结果跟对训练集的预测结果一样好，我们就能自信说模型没有过度拟合．</p><blockquote><p>验证集帮助我们在训练期间了解模型的泛化能力．</p></blockquote><p>相反地，如果模型在训练数据上的结果很好，在验证数据上的结果却不尽人意，这就说明模型已经过拟合了．</p><p>现在我们再来说一说测试集．</p><h4><span id="测试集">测试集</span></h4><p>测试集是一组数据，用于模型训练结束之后对模型的测试。测试集与训练集以及验证集相互独立。</p><p>在我们用训练集训练数据同时用验证集验证过数据之后，我们用模型预测测试集中未标记的数据的输出．</p><p>测试集和另外两个数据集之间的一个主要区别是测试集是不被标记的数据。训练集和验证集是需要进行标记的，我们需要这些标签计算一些训练指标，例如每个epoch的损失和准确度。</p><p>当模型在我们的测试集中预测未标记的数据时，就相当于模型在实际应用中所面临的情形．</p><blockquote><p> 测试集是模型在产品化之前的最后一关，用来测试模型的泛化能力．</p></blockquote><p>我们不给模型提供测试集中数据的标签，目的是模拟在真实情况下，我们并不知道那些需要预测的数据的标签，对这些数据的分类并无先验知识．</p><p>使模型能够完成分类任务，最终的目标是在数据标签未知的情况下能够对数据正确分类．</p><blockquote><p>机器学习和深度学习的最终目标是打造具有泛化能力的模型</p></blockquote><h4><span id="深度学习所用到的数据集总结">深度学习所用到的数据集总结</span></h4><p>下表总结了深度学习中所用的数据集：</p><div class="table-container"><table><thead><tr><th>数据集</th><th>更新权重</th><th>描述</th></tr></thead><tbody><tr><td>训练集</td><td>是</td><td>用于训练模型。训练的目标是使模型适应训练集，同时保证对新数据的泛化能力。</td></tr><tr><td>验证集</td><td>否</td><td>在训练期间使用，以检查模型的繁华能力。</td></tr><tr><td>测试集</td><td>否</td><td>在模型产品化之前，评估模型最终的泛化能力。</td></tr></tbody></table></div><p>希望大家能够了解不同数据集是如何分配数据的，以及如何使用不同类型的数据集。</p><p>划分出三个相互独立的数据集的主要原因是确保模型能够准确预测未见数据，保持良好的泛化能力。当模型不能很好地泛化时，通常是由于过度拟合或欠拟合。我们将[在下一篇文章中介绍这些内容 。下次见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 数据集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入认识神经网络中的损失函数(loss function)</title>
      <link href="/%E6%B7%B1%E5%85%A5%E8%AE%A4%E8%AF%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-function.html"/>
      <url>/%E6%B7%B1%E5%85%A5%E8%AE%A4%E8%AF%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-function.html</url>
      
        <content type="html"><![CDATA[<p>神经网络损失函数详解</p><p>这篇文章带大家细致探讨什么是损失函数，以及它在人工神经网络中的应用．</p><p>我们在讲神经网络的训练的那篇文章已经见过损失函数的概念，随机梯度下降(SGD)通过迭代更新网络中的权重来最小化损失函数．</p><a id="more"></a><p>训练中在每个epoch结束的时候，在训练过程中的每个时期结束时，将使用网络的输出预测和相应输入的真实标签来计算损失。</p><p> 假设我们的模型需要对猫和狗的图像进行分类，并假定猫的标签为0而狗的标签为1。</p><ul><li>猫：0</li><li>狗：1</li></ul><p>现在假设我们将猫的图像传递给模型，并且提供的输出为0.25。在这种情况下，模型的预测和真实标签之间的差异是 0.25 - 0.00 = 0.25。这种差异也称为<em>误差(error)</em>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">误差= 0.25 - 0.00 = 0.25</span><br></pre></td></tr></table></figure><p>对每个输出执行该过程。对于每个epoch，误差在所有输出个体上累积。</p><p>现在让我们考察一个在实践中常用的损失函数－<em>均方误差</em>（MSE）。</p><h3><span id="均方误差mse">均方误差（MSE）</span></h3><p>对于单个样本，均方误差首先计算输出预测值与标签值之间的差异（误差），然后对误差进行平方，这就是MSE对单个输入的操作，就这么简单．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE（输入）=（输出 - 标签）*（输出 - 标签）</span><br></pre></td></tr></table></figure><p>如果一次将多个样本传递给模型（一批样本），需要对所有这些样本的平方误差取均值。</p><p>这里只是对误差函数中的一种－均方误差MSE背后的数学方程做了介绍，我们能够使用的损失函数还有很多．</p><p>我们刚才用于计算单个样本误差的一般方法同样适用于所有不同类型的损失函数。不同的函数有不同的算法，它们对误差的计算过程也不尽相同．我们通过给平方误差取均值来计算MSE，但是其他的损失函数使用不同的算法来决定取什么值．</p><p>如果我们将整个训练集一次性传递给模型（<code>batch_size=1</code>），那么我们需要在每次epoch结束的时候计算损失．</p><p>如果将训练集分成批次(batches)，并且一次一批地传递给模型，这样要在每批次上计算损失。无论采用哪种方法，由于损失的大小取决于权重值，我们希望每次更新权重时都能看到损失的下降。鉴于SGD的目标是最小化损失，我们需要很多次epoch来使损失降到最低。 </p><p><img src="http://cdn.yiyouls.com/losshead.jpg" alt=""></p><h3><span id="用keras代码表示损失函数">用Keras代码表示损失函数</span></h3><p>我们还使用上篇文章定义的模型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(16, input_shape=(1,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(32, activation=&apos;relu&apos;),</span><br><span class="line">    Dense(2, activation=&apos;sigmoid&apos;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>有了模型之后，我们这样编译它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    Adam(lr=.0001), </span><br><span class="line">    loss=&apos;sparse_categorical_crossentropy&apos;, </span><br><span class="line">    metrics=[&apos;accuracy&apos;]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>通过观察<code>compile</code>函数的第二个参数，我们可以看到指定的损失函为<code>loss=&#39;sparse_categorical_crossentropy&#39;</code>。</p><p>在这个例子中，我们使用了称为<em>稀疏分类交叉熵</em>（<em>sparse categorical crossentropy</em>）的损失函数 ，当然我们可以选择别的损失函数，例如MSE。</p><p>目前Keras中可用的损失函数如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mean_squared_error</span><br><span class="line">mean_absolute_error</span><br><span class="line">mean_absolute_percentage_error</span><br><span class="line">mean_squared_logarithmic_error</span><br><span class="line">squared_hinge</span><br><span class="line">hinge</span><br><span class="line">categorical_hinge</span><br><span class="line">logcosh</span><br><span class="line">categorical_crossentropy</span><br><span class="line">sparse_categorical_crossentropy</span><br><span class="line">binary_crossentropy</span><br><span class="line">kullback_leibler_divergence</span><br><span class="line">poisson</span><br><span class="line">cosine_proximity</span><br></pre></td></tr></table></figure><p>希望你现在能对损失函数有一个大致的了解，明白它在神经网络中的工作原理，并且能够在Keras中指定一个损失函数．我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> loss function </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工神经网络是如何学习(learn)的?</title>
      <link href="/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0-learn-%E7%9A%84.html"/>
      <url>/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0-learn-%E7%9A%84.html</url>
      
        <content type="html"><![CDATA[<p>神经网络的学习过程</p><p>这篇文章我们来探讨人工神经网络是怎样学习的．</p><p>本篇内容涵盖损失loss，梯度gradient，学习率lerning rate，epoch，verbose，batch批处理等概念．</p><a id="more"></a><!-- toc --><ul><li><a href="#学习指的是什么">＂学习＂指的是什么？</a></li><li><a href="#损失函数的梯度gradiant">损失函数的梯度(gradiant)</a></li><li><a href="#学习率">学习率</a></li><li><a href="#更新权重">更新权重</a></li><li><a href="#模型学习的过程即权重更新的过程">模型学习的过程即权重更新的过程</a></li><li><a href="#在keras中进行模型训练">在Keras中进行模型训练</a></li></ul><!-- tocstop --><p><img src="http://cdn.yiyouls.com/ann.png" alt=""></p><p>我们上一篇文章已经了解了训练的过程，数据集中的每一个数据都是从前向后，从输入到输出，在整个神经网络中传递，这被称为前向传播．输出的结果依赖于网络中节点连接的权重分配．</p><p>当数据集中的所有数据点都通过了神经网络，我们称完成了一个epoch．</p><blockquote><p>一个epoch是指整个数据集在神经网络中的一次完整遍历</p></blockquote><p>一般来讲，在模型学习的过程中需要多个epoch过程．</p><h4><span id="学习指的是什么">＂学习＂指的是什么？</span></h4><p>模型训练中的＂学习＂到底指的是什么？</p><p>还记得吗，在模型建立之初网络中所有的权重值都是任意选择的．同时，在网络的末端，所有给定的输入都会得到一个输出．</p><p>一旦输出结果，我们就可以通过比较预测值与实际标签，计算本次输出的损失（或者说误差），损失的计算依赖于损失函数的选择，我们会在以后仔细讨论这个问题．</p><h4><span id="损失函数的梯度gradiant">损失函数的梯度(gradiant)</span></h4><p>在计算出损失之后，针对网络内的每个权重计算该损失函数的梯度。<em>梯度</em>这个概念并没有那么深奥，它只是用来表示几个变量函数的导数。</p><p>根据上面的解释，我们先只关注模型的一个权重．</p><p>目前为止，我们计算了单个输出的损失，并且计算了对于单个所选权重的损失梯度。这种计算是使用一种称为<em>反向传播</em>的技术完成的 ，反向传播会在以后重点介绍．</p><p>一旦我们得到了损失函数的梯度值，我们就可以使用这个值来更新模型的权重。梯度的作用是告诉我们从哪个方向可以将损失移向最小值，我们的任务是朝着降低损失的方向移动并逐步接近该最小值。</p><h4><span id="学习率">学习率</span></h4><p>我们将梯度值乘以称为<em>学习率的</em>东西 。学习率通常在0.01到0.0001之间，但实际值可能会有所不同。</p><blockquote><p>学习率告诉我们在最小化方向上应该采取多大步长。</p></blockquote><p>目前大家知道这一点就可以了，在以后的文章中会向大家详细介绍学习率这个概念．</p><h4><span id="更新权重">更新权重</span></h4><p>将梯度值乘以学习率，然后用权重值减去刚刚计算的乘积，得到的值就是更新后的权重值．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">新权重值＝旧权重值－（学习率＊梯度值）</span><br></pre></td></tr></table></figure><p>在上面的讨论中，为了讲清概念，我们仅仅考虑单个权重．实际情况中，不同的权重会有不同的梯度值，我们是依据每个权重来计算梯度值的．</p><p>在每个epoch之后所有的权重值都会进行迭代更新，SGD通过最小化损失函数使得权重越来越接近于最优值</p><h4><span id="模型学习的过程即权重更新的过程">模型学习的过程即权重更新的过程</span></h4><p>当我们训练模型使其从数据中学习的时候，这种权重更新是必要的，只有只有我们才能说模型正在＂学习＂．它学习的是每个权重到底应该赋什么值，这些增量变化会对损失函数造成什么影响．权重的变化使得神经网络越来越＂聪明＂，越来越能够将输入映射到正确的输出．</p><p>通过对＂学习＂的解释，以及上篇文章对模型训练的介绍，我们应该能够对模型的训练和学习有一个大致的了解，我们现在学习如何通过Keras完成这样的训练过程．</p><h4><span id="在keras中进行模型训练">在Keras中进行模型训练</span></h4><p>在训练模型之前我们首先需要建立模型．</p><p>模型的建立是从导入所需的类(classes)开始的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import keras</span><br><span class="line">from keras import backend as K</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Activation</span><br><span class="line">from keras.layers.core import Dense</span><br><span class="line">from keras.optimizers import Adam</span><br><span class="line">from keras.metrics import categorical_crossentropy</span><br></pre></td></tr></table></figure><p>之后是定义模型(sequential model)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(16, input_shape=(1,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(32, activation=&apos;relu&apos;),</span><br><span class="line">    Dense(2, activation=&apos;sigmoid&apos;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>在训练模型之前，需要对模型进行编译(compile），像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    Adam(lr=.0001), </span><br><span class="line">    loss=&apos;sparse_categorical_crossentropy&apos;, </span><br><span class="line">    metrics=[&apos;accuracy&apos;]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>给<code>compile()</code>函数传递优化器(optimizer)，损失函数(loss)，以及所需的精准度度量(metrics)．我们在这里指定的优化器被称为<code>Adam</code>．<code>Adam</code>是SGD的一个变种．在<code>Adam</code>构造函数内指定学习率，这里写的是<code>Adam(lr=.0001)</code>，表示学习率为<code>0.0001</code>.</p><p>最后，将模型与数据拟合(fit)，把模型拟合到数据是指在数据上训练模型，通过下面的代码进行此操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.fit(</span><br><span class="line">    scaled_train_samples, </span><br><span class="line">    train_labels, </span><br><span class="line">    batch_size=10, </span><br><span class="line">    epochs=20, </span><br><span class="line">    shuffle=True, </span><br><span class="line">    verbose=2</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>scaled_train_samples</code> 是一个由训练样本组成的numpy数组<sup><a href="#fn_1" id="reffn_1">1</a></sup>．</p><p><code>train_labels</code> 也是一个numpy数组，由训练样本的相应标签组成．</p><p><code>batch_size=10</code> batch批处理，指定应该一次向模型发送多少训练样本。</p><p><code>epochs=20</code> 意味着完整的训练集（所有样本）将被传递给模型共20次。</p><p><code>shuffle=True</code> 表示在传递给模型之前应首先对数据进行混洗(shuffle)。</p><p><code>verbose=2</code> 表示在模型训练中显示多少日志<sup><a href="#fn_2" id="reffn_2">2</a></sup>。</p><p>运行此代码会得到以下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20 0s - loss: 0.6400 - acc: 0.5576</span><br><span class="line">Epoch 2/20 0s - loss: 0.6061 - acc: 0.6310</span><br><span class="line">Epoch 3/20 0s - loss: 0.5748 - acc: 0.7010</span><br><span class="line">Epoch 4/20 0s - loss: 0.5401 - acc: 0.7633</span><br><span class="line">Epoch 5/20 0s - loss: 0.5050 - acc: 0.7990</span><br><span class="line">Epoch 6/20 0s - loss: 0.4702 - acc: 0.8300</span><br><span class="line">Epoch 7/20 0s - loss: 0.4366 - acc: 0.8495</span><br><span class="line">Epoch 8/20 0s - loss: 0.4066 - acc: 0.8767</span><br><span class="line">Epoch 9/20 0s - loss: 0.3808 - acc: 0.8814</span><br><span class="line">Epoch 10/20 0s - loss: 0.3596 - acc: 0.8962</span><br><span class="line">Epoch 11/20 0s - loss: 0.3420 - acc: 0.9043</span><br><span class="line">Epoch 12/20 0s - loss: 0.3282 - acc: 0.9090</span><br><span class="line">Epoch 13/20 0s - loss: 0.3170 - acc: 0.9129</span><br><span class="line">Epoch 14/20 0s - loss: 0.3081 - acc: 0.9210</span><br><span class="line">Epoch 15/20 0s - loss: 0.3014 - acc: 0.9190</span><br><span class="line">Epoch 16/20 0s - loss: 0.2959 - acc: 0.9205</span><br><span class="line">Epoch 17/20 0s - loss: 0.2916 - acc: 0.9238</span><br><span class="line">Epoch 18/20 0s - loss: 0.2879 - acc: 0.9267</span><br><span class="line">Epoch 19/20 0s - loss: 0.2848 - acc: 0.9252</span><br><span class="line">Epoch 20/20 0s - loss: 0.2824 - acc: 0.9286</span><br></pre></td></tr></table></figure><p>上面的输出为每个epoch提供以下参考值：</p><ol><li>epoch编号</li><li>持续时间（秒）</li><li>损失</li><li>精度</li></ol><p>从数据中可以看出，随着epoch的进行，loss损失的值不断下降，精度不断提高．</p><p>这就是在Keras中训练模型的普遍方法，希望你可以对训练过程有一个大致的了解，明白模型到底是怎样＂学习＂的，也能够自己在Keras中训练一个模型．我们下篇文章再见！</p><blockquote id="fn_1"><sup>1</sup>. numpy数组是数据的储存形式，使用的是Python语言的NumPy扩展库，支持大量的维度数组与矩阵运算．pytorch框架把这种数据结构称为张量(tensor)．<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2"><sup>2</sup>. verbose:显示日志．verbose = 0 为不在标准输出流输出日志信息， verbose = 1 为输出进度条记录， verbose = 2 为每个epoch输出一行记录． 注意： 默认为 1<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何训练(train)人工神经网络？</title>
      <link href="/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F.html"/>
      <url>/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9F.html</url>
      
        <content type="html"><![CDATA[<h4><span id="神经网络的训练">神经网络的训练</span></h4><p>这篇文章带大家学习如何训练一个人工神经网络．之前的文章中我们学习了如何构建一个简单的人工神经网络，当我们把一个神经网络配置好之后，下一步就是来训练它了．</p><a id="more"></a><!-- toc --><ul><li><a href="#什么是训练">什么是训练？</a><ul><li><a href="#优化算法optimization-algorithm">优化算法(optimization algorithm)</a></li><li><a href="#损失函数loss-function">损失函数(loss function)</a></li></ul></li><li><a href="#结论">结论</a></li></ul><!-- tocstop --><h3><span id="什么是训练">什么是训练？</span></h3><p>模型的训练过程，基本来说就是一个解决优化问题的过程，优化模型中的权重．我们的任务是找到最准确地将输入数据映射到正确输出类的权重。这种映射是网络<em>学习</em>而来的。</p><p>在关于层的介绍的那篇文章中我们提到了这个概念．我们在构建模型的时候，可以给这些节点的连接分配任意的权重，在训练中对这些权重进行迭代更新使其向最优值移动．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 伪代码</span><br><span class="line">def train(model):</span><br><span class="line">    model.weights.update()</span><br></pre></td></tr></table></figure><h4><span id="优化算法optimization-algorithm">优化算法(optimization algorithm)</span></h4><p>使用我们称之为优化算法(optimization algorithm)的方法来优化权重。不同的优化算法有不同的优化流程。我们用<em>优化器(optimizer)</em>一词来指代所选择的优化算法。最广为人知的优化器称为<em>随机梯度下降(stochastic gradient descent)</em>，或更简单地称为 SGD。</p><p>当处理优化问题时，必须先有一个优化目标，现在让我们考虑一下SGD在优化模型权重时的优化目标。</p><p> SGD的目标是优化一些给定的函数，这些函数被称为<em>损失函数</em>．SGD更新模型的权重，使得此损失函数尽可能接近其最小值。</p><h4><span id="损失函数loss-function">损失函数(loss function)</span></h4><p>我们在模型优化中可以用的损失函数有很多，一个常见的损失函数是<em>均方误差</em>（MSE）。具体使用哪种损失函数是由我们在实践中决定的。现在，让我们先从一般层面认识一下损失函数，之后再更加详细地研究具体的损失函数。</p><p>我们所说的损失指的是什么？在训练过程中，我们给模型提供数据和数据相应的标签．</p><p>例如，假设我们想要训练一个用来分类图像中是猫的还是狗的模型。我们给这个模型提供猫和狗的图像，以及说明每个图是猫是狗的标签。</p><p>我们现在把一只猫的图像传递给模型，当猫的图像数据从网络中传递，前向传播结束后，模型会产生一个输出．这个输出包含了模型认为这个图像是猫是狗的信息．</p><p>具体来讲，这个输出反映的是图像是猫或是狗的概率．比如，模型给图像是猫分配７５％的概率，给图像是狗分配２５％的概率．在这种情况下，模型为图像是猫赋予更大的可能性．</p><ul><li>有75％的可能性是猫</li><li>25％的几率它是一只狗</li></ul><p>这其实跟人类的思维方式很类似，我们所有的判断都是基于猜想和预测．</p><p><img src="http://cdn.yiyouls.com/humanlearn.jpg" alt=""></p><p>所谓损失是神经网络对图像的猜测跟图像的标签之间的差距，SGD尝试最小化这种误差，使得模型猜测尽可能地精确．</p><p>在我们把所有的数据都传递给模型之后，我们会重复这一过程，让数据在模型中一次次传递．这种重复的数据传递就是训练．模型在训练的过程中能够＂学到＂很多信息，我们在下一篇文章会详细介绍．SGD通过反复的迭代，最终能够从数据中学习．</p><h3><span id="结论">结论</span></h3><p>我们现在已经了解到数据在网络中前向传播的过程中大致发生了什么．在下一篇文章中我们会介绍模型是怎样通过多次前向传播学习的，以及SGD最小化损失函数的具体方法．</p><p>这篇文章提到了很多新的概念，例如优化器，损失，我们会在以后的文章中分开来讲这些内容．记得去查看我们最新的博文．</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 训练 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何理解神经网络中的激活函数(ativation functions)?</title>
      <link href="/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-ativation-functions.html"/>
      <url>/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-ativation-functions.html</url>
      
        <content type="html"><![CDATA[<p>神经网络中的激活函数</p><p>这篇文章向大家解释激活函数到底是什么，以及如何在神经网络中使用激活函数．我会向大家介绍几种常见的激活函数，向大家展示这些激活函数如何在Keras中以代码的形式呈现．</p><a id="more"></a><p>上篇文章在介绍神经网络中层的概念的时候，已经提到过激活函数，它们经常出现在层之后，我们这节就更加深入地认识这个概念．</p><!-- toc --><ul><li><a href="#什么是激活函数">什么是激活函数？</a></li><li><a href="#激活函数有什么作用">激活函数有什么作用？</a><ul><li><a href="#sigmoid激活函数">Sigmoid激活函数</a></li><li><a href="#激活函数的由来">激活函数的由来</a></li><li><a href="#relu激活函数">Relu激活函数</a></li><li><a href="#为什么要使用激活函数">为什么要使用激活函数？</a></li><li><a href="#关于relu函数是非线性的证明">关于Relu函数是非线性的证明</a></li><li><a href="#在keras中用代码表示激活函数">在Keras中用代码表示激活函数</a></li></ul></li></ul><!-- tocstop --><h3><span id="什么是激活函数">什么是激活函数？</span></h3><p>让我们给出一个激活函数的定义：</p><blockquote><p>在人工神经网络中，激活函数是将节点的输入映射到其对应输出的函数。</p></blockquote><p>在上篇文章的图示中我们已经看到，层中的每个节点会得到每个传入连接的加权和，之后将这个加权和传递给激活函数．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node output = activation(weighted sum of inputs)</span><br></pre></td></tr></table></figure><p>激活函数执行某种类型的操作以将总和转换为通常在某个下限和某个上限之间的数字。这种转变通常是非线性转换。我们在以后会再次提到这种非线性变换．</p><h3><span id="激活函数有什么作用">激活函数有什么作用？</span></h3><p>激活函数的这种变换意义在哪里？激活函数是受什么启发？为了更好地理解激活函数，首先带大家看几个激活函数的例子．</p><h4><span id="sigmoid激活函数">Sigmoid激活函数</span></h4><p>Sigmoid函数接受输入并执行以下操作：</p><ul><li>对于负输入，sigmoid会将输入转换为接近零的数字。</li><li>对于正输入，sigmoid会将输入转换为接近1的数字。</li><li><p>对于接近零的输入，sigmoid会将输入转换为0到1之间的某个数字。</p><p><img src="http://cdn.yiyouls.com/sigmoid.svg" alt=""></p></li></ul><p>可以看出，对于sigmoid函数，０是它的下界，１是它的上界．</p><p>我们现在理解了这样一个激活函数的数学功能，那激活函数到底是受到什么的启发？</p><h4><span id="激活函数的由来">激活函数的由来</span></h4><p>激活函数同样是受到大脑活动的生物学特征的启发，我们知道不同类型的刺激会使不同区域的神经元被激活．</p><p>例如当你问道一些令人愉悦的东西，像刚出炉的点心，你大脑中某些特定的神经元就会被激活．但是当你闻到一些难闻的东西，像发酸的牛奶，这样就会激活你大脑中另外一些区域的神经元．</p><p><img src="http://cdn.yiyouls.com/cookie.jpg" alt=""></p><p>在我们大脑的褶皱深处，某些神经元要么正在被激活，要么没有。这种情形可以用数学符号表示，我们用０表示未被激活，用１表示被激活。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 伪代码</span><br><span class="line">if (smell.isPleasant()) &#123;</span><br><span class="line">    neuron.fire();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用人工神经网络中的Sigmoid激活函数，我们把神经元转换到在0和1之间的数字，如果越接近1，神经元被激活得越多，而越接近０，神经元被激活得越少。</p><h4><span id="relu激活函数">Relu激活函数</span></h4><p>激活函数并不总是将输入转换为0到1之间的数字。我们现在看一下ReLU激活函数．</p><p>ReLU作为目前最广泛使用的激活函数之一，它将输入转换为输入值本身与０之间更大的那个．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ReLU(x) = max(0, x)</span><br></pre></td></tr></table></figure><p>因此，如果输入小于或等于零，则relu将输出零。如果输入大于零，则relu将输出输入值本身。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 伪代码</span><br><span class="line">function relu(x) &#123;</span><br><span class="line">    if (x &lt;= 0) &#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数背后的想法是，神经元越积极，被激活的就越多．</p><p>目前我们已经讨论了Sigmoid和relu函数，当然还有其他的一些类型的函数，它们会对输入做其他类型的变换．</p><h4><span id="为什么要使用激活函数">为什么要使用激活函数？</span></h4><p>要理解我们使用激活函数的原因，我们首先需要了解线性函数。</p><p>假设$f$是集合$X$上的函数 。  </p><p>假设$a$和$b$在$X$中。  </p><p>假设$x$是实数。 </p><p> 当且仅当以下情况时 ，函数 f被称为线性函数：</p><p> $f(a+b)=f(a)+f(b)$  并且　$f(xa)=xf(a)$</p><p>线性函数的一个重要特征是两个线性函数的组合也是线性函数。这意味着，即使在非常深的神经网络中，如果我们在前向传递过程中只对数据值进行线性变换，深度学习网络中从输入到输出的映射也将是线性的。</p><p>我们在深度学习神经网络中想要得到的映射往往要比线性映射复杂得多．</p><p>这个时候就需要用到激活函数了．大多数激活函数都是非线性的，这是我们有意为之的选择．具有非线性变换的激活函数允许神经网络计算任意复杂的函数。</p><h4><span id="关于relu函数是非线性的证明">关于Relu函数是非线性的证明</span></h4><p>如何证明Relu函数是非线性的．我们下面试着来证明Relu不是线性变换．</p><p>对于每个实数$x$，我们将函数$f$定义为：</p><p>$f(x)=relu(x)$</p><p>假设$a$是实数并且$a&lt;0$.</p><p>因为$a&lt;0$, 我们有，</p><p>$f(-1a)=max(0,-1a)&gt;0$  并且  $(-1)f(a)=(-1)max(0,a)=0$</p><p>由此可得，</p><p>$f(-1a)\ne (-1)f(a)$</p><p>由此证明函数$f$是非线性的．</p><h4><span id="在keras中用代码表示激活函数">在Keras中用代码表示激活函数</span></h4><p>现在我们学习如何在Keras顺序模型中指定一个激活函数</p><p>定义激活函数有两种基本的方式，首先需要导入类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense, Activation</span><br></pre></td></tr></table></figure><p>之后我们可以在层构造函数中指定激活函数，像这样，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(5, input_shape=(3,), activation=&apos;relu&apos;)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>这样我们就有了一个<code>dense</code>类型的层，并且指定本层的激活函数为<code>activation=&#39;relu&#39;</code></p><p>第二种方法是在模型实例化之后将层和激活函数添加到我们的模型中，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(5, input_shape=(3,)))</span><br><span class="line">model.add(Activation(&apos;relu&apos;))</span><br></pre></td></tr></table></figure><p>请记住</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node output = activation(weighted sum of inputs)</span><br></pre></td></tr></table></figure><p>在上面的例子中，<code>dense</code>层每个节点的输出等于输入加权和的relu值，即</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node output = relu(weighted sum of inputs)</span><br></pre></td></tr></table></figure><p>希望你现在可以对激活函数如何适用于神经网络结构有个大概的认识，能够了解它们的功能和作用，并且学会在Keras中调用它们．我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> 激活函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何理解神经网络中层(layer)的概念？</title>
      <link href="/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%B1%82-layer-%E7%9A%84%E6%A6%82%E5%BF%B5%EF%BC%9F.html"/>
      <url>/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%B1%82-layer-%E7%9A%84%E6%A6%82%E5%BF%B5%EF%BC%9F.html</url>
      
        <content type="html"><![CDATA[<p>如何理解神经网络中层(layer)的概念?</p><p>我们在之前的文章中认识了只有三个层的神经网络，但在很多时候我们有多个隐藏层，这篇文章探讨如何深入理解神经网络中层的概念，并提供一个多层神经网络的构建方法．</p><a id="more"></a><!-- toc --><ul><li><a href="#神经网络的层">神经网络的层</a></li><li><a href="#为什么有不同类型的层">为什么有不同类型的层？</a></li><li><a href="#人工神经网络示例">人工神经网络示例</a><ul><li><a href="#层的权重">层的权重</a></li><li><a href="#神经网络正向传播">神经网络正向传播</a></li><li><a href="#找到最佳权重">找到最佳权重</a></li></ul></li><li><a href="#用keras代码定义神经网络">用Keras代码定义神经网络</a></li></ul><!-- tocstop --><h3><span id="神经网络的层">神经网络的层</span></h3><p><img src="http://cdn.yiyouls.com/cover_1.jpg" alt=""></p><p>为了更加深入地学习，我们需要更好地理解人工神经网络中层的概念，以及如何在keras中给一个顺序模型添加更多的层．</p><p>上篇文章我们学习了ANN中的神经元是如何组织成层结构的．我们用了一个<code>dense</code>层的例子，这是一种全连接．当然，层的类型不止这一种，keras中有各种各样的层类型：</p><ul><li>Dense层（全连接层）</li><li>卷积(convolutional)层</li><li>池化(pooling)层</li><li>递归(recurrent)层</li><li>正则化(normalization)层</li></ul><h3><span id="为什么有不同类型的层">为什么有不同类型的层？</span></h3><p>不同的层对其输入执行不同的转换，并且某些层比其他层更适合某些特定任务。例如，卷积层通常用于处理图像数据的模型中。递归层用于处理时间序列数据的模型，完全连接层（顾名思义）将每个输入完全连接到其图层中的每个输出。</p><p>这篇文章将继续从宏观层面理解层的概念，随着我们对深度学习认识的深入，我们会更加了解特定层类型的特殊作用．</p><h3><span id="人工神经网络示例">人工神经网络示例</span></h3><p>我们一起来看下面例子中的ANN模型：</p><p><img src="http://cdn.yiyouls.com/4layers.png" alt=""></p><p>对于这个例子，第一层，即输入层，由八个节点组成，每个节点代表数据集中给定样本的某个要素．</p><p>我们可以知道，来自数据集的单个样本由八个维度组成．当我们从数据集中选择样本并将此样本传递给模型时，样本中包含的八个值中的每一个都将提供给输入层中的相应节点。</p><p>我们可以看到八个输入节点中的每一个都连接到下一层中的每个节点。</p><p>第一层和第二层之间的每个连接将来自前一节点的输出传送到接收节点的输入（从左到右）。中间有六个节点的两个层都是隐藏层，因为它们位于输入和输出层之间。</p><h4><span id="层的权重">层的权重</span></h4><p>每两个节点之间的连接都有一个相关的权重，这个权重是一个数字。</p><p>每个权重代表两个节点之间连接的强度。当网络在输入层中的给定节点处接收输入时，该输入通过连接传递到下一节点，并且输入将乘以分配给该连接的权重。</p><p>对于第二层的每个节点，计算每个传入连接的加权和。然后将该总和传递给激活函数，该激活函数对给定的总和执行某种类型的变换。例如，激活函数可以将和变换为0和1之间的数。实际转换将根据使用的激活函数而变化。更多关于激活功能的介绍之后会提到．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node output = activation(weighted sum of inputs)</span><br></pre></td></tr></table></figure><h4><span id="神经网络正向传播">神经网络正向传播</span></h4><p>一旦我们获得给定节点的输出，获得的输出就是作为输入传递给下一层节点的值。</p><p>重复此过程直到到达输出层。输出层中的节点数取决于我们可能的输出个数或预测类的数量。在示例中，我们的预测类有四个。</p><p>假设我们的模型的任务是对四种动物进行分类。输出层中的每个节点将代表四种可能性之一。例如，这些动物可以是猫，狗，马或牛。具体怎样分类取决于数据集中有多少个类。</p><p>对于来自数据集的给定样本，从输入层到输出层的整个过程称为网络的前向传播。</p><h4><span id="找到最佳权重">找到最佳权重</span></h4><p>在模型学习时，更新和优化所有连接的权重，使得输入数据点映射到正确的输出预测类。我们以后会学到更多关于此优化过程 。</p><p>我们已经对神经网络模型中层是如何工作的有了一个大致了解。现在让我们看看如何用Keras代码表示我们的模型。</p><h3><span id="用keras代码定义神经网络">用Keras代码定义神经网络</span></h3><p>在我们之前的讨论中，我们学习了如何使用Keras构建顺序模型。我们现在把它应用到本文中所讲的这个示例中。</p><p>我们从定义一个<code>Dense</code>对象数组开始，即定义各个层。然后将该数组传递给顺序模型的构造函数。</p><p>我们的神经网络是长这样：</p><p><img src="http://cdn.yiyouls.com/4layers.png" alt=""></p><p>鉴于此，我们有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">layers = [</span><br><span class="line">    Dense(6, input_shape=(8,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(6, activation=&apos;relu&apos;),</span><br><span class="line">    Dense(4, activation=&apos;softmax&apos;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>注意<code>Dense</code>数组中指定的第一个对象不是输入层。第一个<code>Dense</code>对象是第一个隐藏层。输入层被指定为第一个<code>Dense</code>对象构造函数中的参数。</p><p>输入层共有８个节点，因此输入层形状被指定为<code>input_shape=(8,)</code>，第一个隐藏层有六个节点，第二个隐藏层也是如此，输出层有四个节点。</p><p>我们通过<code>activation=&#39;relu&#39;</code>为两个隐藏层使用一个名为relu的激活函数，通过<code>activation=&#39;softmax&#39;</code> 为输出层使用一个名为softmax的激活函数。我们将在下一篇关于激活功能的文章中更详细地介绍这些功能。</p><p>完整代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense, Activation</span><br><span class="line"></span><br><span class="line">layers = [</span><br><span class="line">    Dense(6, input_shape=(8,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(6, activation=&apos;relu&apos;),</span><br><span class="line">    Dense(4, activation=&apos;softmax&apos;)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">model = Sequential(layers)</span><br></pre></td></tr></table></figure><p>以上是如何在Keras中表示一个拥有四个层的神经网络。通过这篇文章的介绍，希望你能够对神经网络中有哪些层及其运行方式有一个大致的了解。我们下篇文章再见！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
            <tag> layer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是人工神经网络ANNs?</title>
      <link href="/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CANNs.html"/>
      <url>/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CANNs.html</url>
      
        <content type="html"><![CDATA[<p>什么是人工神经网络(artificial neural network)?</p><p>在上一篇文章中我们把深度学习定义为机器学习的子领域，深度学习所用到的算法是受大脑神经网络的结构和功能的启发．因为这个浅显的的原因，深度学习中使用的模型被称为人工神经网络（ANN）。</p><a id="more"></a><!-- toc --><ul><li><a href="#人工神经网络图示">人工神经网络图示</a></li><li><a href="#keras顺序sequential模型">Keras顺序(sequential)模型</a></li></ul><!-- tocstop --><p><img src="http://cdn.yiyouls.com/cover_1.jpg" alt="cover_1"></p><p>让我们给人工神经网络下一个定义。</p><blockquote><p>人工神经网络是一种计算系统，由一系列以特定方式组织的单元(unit)组成，这些单元被称神经元(neurons)，它们的组织方式被称为层(layers)结构，不同层的神经元的连接形成所谓的网络．</p></blockquote><p>不同层的神经元之间的每个连接将信号从一个神经元传递到另一个神经元。接收到信号的神经元处理信号并向网络内与其连接的下游神经元发信号。注意，神经元通常也称为 <em>节点</em>(nodes)，同一层的节点之间无连接。</p><p>节点组合为层状结构，从广义的层面，每个ANN中有三种类型的层：</p><ol><li>输入层　input layer</li><li>隐藏层　hidden layer</li><li>输出层　output layer</li></ol><p>不同的层对其输入执行不同类型的转换。数据在神经网络中的流动从输入层开始，然后在隐藏层中移动，直到到达输出层。这被称为数据在网络中的前向传递。输入层和输出层之间的层被称为隐藏层。</p><p>现在让我们考察每种类型的层所包含的节点数量：</p><ol><li>输入层 - 输入数据的每个维度形成一个节点。</li><li>隐藏层 - 每个隐藏层的节点数可以任意指定。</li><li><p>输出层 - 每个输出结果形成一个节点。</p><p>现在我们已经对ANN的定义和结构有了一个大体概念，下面让我们试着用图示的方法来解释这些概念。</p></li></ol><h3><span id="人工神经网络图示">人工神经网络图示</span></h3><p>我们一起来分析下图所展示的一个神经网络:</p><p><img src="http://cdn.yiyouls.com/ann.png" alt=""></p><p>该ANN共有三层。左侧的图层是输入层，右侧的图层是输出层，中间的图层是隐藏层。每个层都由神经元（节点）组成，这里我们用圆圈表示这些节点，让我们数一数这个网络的每一层有多少个节点。</p><p> 每层中的节点数：</p><ol><li>输入层（左）：2个节点</li><li>隐藏层（中）：3个节点</li><li>输出层（右）：2个节点</li></ol><p>该网络在输入层中有两个节点，这告诉我们该网络的每个输入必须具有两个维度，例如<em>体重</em>和<em>身高</em>。</p><p>该网络在输出层中有两个节点，这告诉我们通过网络向前（从左到右）传递的每个输入都有两个可能的输出。例如， <em>偏胖</em>或 <em>偏瘦</em>可能是两个输出类。请注意，输出类也称为预测类。</p><p> 在掌握了这些理论知识之后，让我们看看如何在Keras中使用代码构建ANN。</p><h3><span id="keras顺序sequential模型">Keras顺序(sequential)模型</span></h3><p>在Keras，我们可以构建所谓的顺序模型。Keras将顺序模型定义为线性层结构的顺序堆栈。因为我们刚刚学到神经元的组织方式就是层结构，顺序模型刚好是我们所需要的。</p><p>Keras通过顺序模型实现人工神经网络的构造。那就让我们看看如何使用Keras构建一个非常简单的顺序模型。</p><p>首先，我们在Keras中导入所需的类。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense, Activation</span><br></pre></td></tr></table></figure><p>然后，我们创建一个名为<code>model</code>的变量，将一个Sequential对象的实例赋值予它．</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential(layers)</span><br></pre></td></tr></table></figure><p>对于构造函数，我们传递一个<code>Dense</code>对象数组 。每个<code>dense</code>对象的调用即是每一个层。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">layers = [</span><br><span class="line">    Dense(3, input_shape=(2,), activation=&apos;relu&apos;),</span><br><span class="line">    Dense(2, activation=&apos;softmax&apos;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><em>dense</em> 这个词表示这些层的类型，也就是说我们构造的这些层都属于<code>dense</code>类型。<code>dense</code>是一种特殊类型的层，随着学习的深入，我们还会看到许多其他的类型。</p><p>现在，我们只需知道<code>dense</code>是ANN中最基本的层类型，并且<code>dense</code>层的每个输出是由它的输入所计算的。 </p><p>回看图示中从隐藏层到输出层的箭头，我们可以知道隐藏层中的每个节点都连接到输出层中的所有节点。这说明图示中的输出层是一个<code>dense</code>层。同样我们也可以看出隐藏层也是<code>dense</code>类型。</p><p>每层中传递给<code>dense</code>层构造函数的第一个参数表示该层一共有多少神经元。</p><p>输入形状参数 <code>input_shape=(2,)</code>告诉我们输入层有多少神经元，在这个例子中有两个神经元。</p><p>最后还有一个参数也就是说所谓的激活函数。</p><ol><li><code>activation=&#39;relu&#39;</code></li><li><code>activation=&#39;softmax&#39;</code></li></ol><p>在之后的文章中会详细介绍激活函数，现在你只需要知道激活函数是一种非线性函数，一般用在<code>dense</code>层之下．</p><p>以上是在keras中最简单的一个模型定义方法，如果想要了解更多关于keras的知识，请参考本博客关于keras的系列教程，这篇文章希望你可以了解ANN是什么，如何用keras构造一个神经网络．更进一步学习请关注下一篇博文．</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ANNs </tag>
            
            <tag> 人工神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11大最常用静态网站建站工具，你用过几个？</title>
      <link href="/11%E5%A4%A7%E6%9C%80%E5%B8%B8%E7%94%A8%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99%E5%BB%BA%E7%AB%99%E5%B7%A5%E5%85%B7%EF%BC%8C%E4%BD%A0%E7%94%A8%E8%BF%87%E5%87%A0%E4%B8%AA%EF%BC%9F.html"/>
      <url>/11%E5%A4%A7%E6%9C%80%E5%B8%B8%E7%94%A8%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99%E5%BB%BA%E7%AB%99%E5%B7%A5%E5%85%B7%EF%BC%8C%E4%BD%A0%E7%94%A8%E8%BF%87%E5%87%A0%E4%B8%AA%EF%BC%9F.html</url>
      
        <content type="html"><![CDATA[<p>在进行下一步操作之前，你首先要明白，你通过我们上篇博文所介绍的方式建立的网站，是一种静态网站，这个是最近特别流行的静态网站搭建博客的技术，非常适合让站长专注于内容创作而非网站本身的维护．</p><p>为什么不用动态网站例如大名鼎鼎的wordpress呢？</p><a id="more"></a><p>究其原因，还是与博客类型网站本身的定位有关．静态网站和动态网站相比有如下好处：</p><ul><li>免费。静态网站占用的系统资源少。如果挂到github pages上，只要注册一个域名就可以了。</li><li>高速。不经过php解析器，不用数据库，速度比动态网站快</li><li>安全。由于静态网站的简洁，免疫很多web攻击方式。</li><li>服务器端配置简单。只需要一个web server（apache、nginx）。</li><li>非常容易维护。静态网站生成工具能从简单的纯文本文件生成一个网站/博客。尤其是对Markdown文法的支持，可以让你非常快捷地生成图文并茂的博文．</li></ul><p>关于Markdown语法，我会用专门的一篇博文来介绍Tyora下怎么使用．不单单是写博文，各种各样的文字工作用上Markdown语法后，可以让你的效率和创造力倍增．</p><p>目前对于搭建静态网站，有很多有常用的开源工具．以下就是这些常用工具的介绍：</p><h1><span id="jekyll">Jekyll</span></h1><p><a href="http://jekyllrb.com/" target="_blank" rel="noopener"><strong>Jekyll</strong></a>做为GitHub Pages的构建工具（Ruby语言），使它成为最流行的静态网站生成工具。Jekyll的流行也因为它非常简单，只需要基础的web开发基础。你可以使用它轻易的把文本转换为自定义的网站/博客。</p><p>如果你有wordpress或其他博客站点，你可以导入到Jekyll中。Jekyll支持插件、标签等等。</p><p><img src="http://cdn.yiyouls.com/jekyll.png" alt="Jekyll"></p><blockquote><p>Github Pages：<a href="https://pages.github.com/" target="_blank" rel="noopener">https://pages.github.com</a></p><p>开始使用Jekyll：<a href="http://jekyllrb.com/docs/quickstart/" target="_blank" rel="noopener">http://jekyllrb.com/docs/quickstart/</a></p></blockquote><h1><span id="octopress">Octopress</span></h1><p><a href="http://octopress.org/" target="_blank" rel="noopener"><strong>Octopress</strong></a>是基于Jekyll的博客生成工具，它简化了Jekyll的操作，可以让你更舒服的创作。Octopress的一大优势是它插件很多，并且兼容Jekyll的官方插件。</p><p>Octopress支持内建的社交平台（Twitter, Google+），Disqus评论和Google Analytics。</p><p><img src="http://cdn.yiyouls.com/octopress.png" alt="Octopress"></p><blockquote><p>Octopress的文档：<a href="http://octopress.org/docs/" target="_blank" rel="noopener">http://octopress.org/docs/</a></p></blockquote><h1><span id="hexo">Hexo</span></h1><p><a href="https://hexo.io/" target="_blank" rel="noopener"><strong>Hexo</strong></a>是用Node.js编写的博客框架。这个静态网站生成工具非常快，使用它构建一个完整的网站只需要几秒钟。Hexo支持所有的GitHub Markdown特性，并支持大多数Octopress插件。</p><p>从其他博客平台迁移到hexo非常容易。</p><p><img src="http://cdn.yiyouls.com/hexo.png" alt="Hexo"></p><blockquote><p>[Hexo的文档]<a href="https://hexo.io/docs/" target="_blank" rel="noopener">https://hexo.io/docs/</a></p></blockquote><h1><span id="hugo">Hugo</span></h1><p>[Hugo]<a href="http://gohugo.io/" target="_blank" rel="noopener">http://gohugo.io/</a>是另一个流行的静态网站生成工具，它是使用go语言编写，并且使用Markdown语法。官网对它的描述：</p><blockquote><p>This application does not depend on administrative privileges, databases, interpreters, or external libraries, and still works like a charm. Websites or blogs built with Hugo can be hosted on any web host including GitHub Pages, S3, and Dropbox.</p></blockquote><p><img src="http://cdn.yiyouls.com/hugo.png" alt="Hugo"></p><blockquote><p>开始使用Hugo：<a href="http://gohugo.io/overview/quickstart/" target="_blank" rel="noopener">http://gohugo.io/overview/quickstart/</a></p></blockquote><h1><span id="pelican">Pelican</span></h1><p><a href="http://getpelican.com/" target="_blank" rel="noopener"><strong>Pelican</strong></a>是使用Python编写的静态网站生成工具。它支持用reStructuredText, Markdown, 和AsciiDoc创作网站内容。Pelican支持Jinja模版引擎，结果是，它支持很多自定义主题。</p><p>gongneng<img src="http://cdn.yiyouls.com/Pelican.png" alt="Pelican"></p><blockquote><p>开始使用Pelican：<a href="http://docs.getpelican.com/en/3.6.3/install.html" target="_blank" rel="noopener">http://docs.getpelican.com/en/3.6.3/install.html</a></p></blockquote><h1><span id="middleman">Middleman</span></h1><p><a href="https://middlemanapp.com/" target="_blank" rel="noopener">Middleman</a> －中间人，又一个使用Ruby编写的静态网站生成工具。它提供怎么使用和自定义的文档，方便你自定义你的网站。</p><blockquote><p>Middleman is a static site generator using all the shortcuts and tools in modern web development.</p></blockquote><p><img src="http://cdn.yiyouls.com/middleman.png" alt="Middleman"></p><blockquote><p>开始使用Middleman：<a href="https://middlemanapp.com/basics/install/" target="_blank" rel="noopener">https://middlemanapp.com/basics/install/</a></p></blockquote><h1><span id="metalsmith">Metalsmith</span></h1><p><a href="http://www.metalsmith.io/" target="_blank" rel="noopener">Metalsmith</a>是简单、高效、pluggable静态网站生成工具，它使用nodejs编写。Metalsmith和其他工具的最大区别是它的所有东西都由插件处理，并且插件可以重用。只要决定网站的功能，然后找到相关插件，组合到一起，ok，ready to go!</p><p>Metalsmith也可以生成PDF、电子书、文档等等。</p><p><img src="http://cdn.yiyouls.com/metalsmith.png" alt="Metalsmith"></p><blockquote><p>开始使用Metalsmith：<a href="http://www.metalsmith.io/" target="_blank" rel="noopener">http://www.metalsmith.io/</a></p></blockquote><h1><span id="docpad">DocPad</span></h1><p><a href="http://docpad.org/" target="_blank" rel="noopener">DocPad</a>自带建立好的网站主架，允许你快速的建立功能完整的网站。这个工具支持CoffeeScript、Ruby、PHP、Stylus等等。</p><blockquote><p>DocPad removes limitations and closes the gap between experts and beginners. Designers and developers can create websites faster than ever before.</p></blockquote><p><img src="http://cdn.yiyouls.com/docpad.png" alt="DocPad"></p><blockquote><p>开始使用DocPad：<a href="http://docpad.org/docs/install" target="_blank" rel="noopener">http://docpad.org/docs/install</a></p></blockquote><h1><span id="wintersmith">Wintersmith</span></h1><p><a href="http://wintersmith.io/" target="_blank" rel="noopener">Wintersmith</a>是极简的、可扩展的静态网站生成工具，它使用Nodejs编写。它同样支持插件。Wintersmith的项目基于目录结构，可以方便的移植旧站点。</p><p><img src="http://cdn.yiyouls.com/wintersmith.png" alt="Wintersmith"></p><blockquote><p>开始使用Wintersmith：<a href="https://github.com/jnordberg/wintersmith#quick-start" target="_blank" rel="noopener">https://github.com/jnordberg/wintersmith#quick-start</a></p></blockquote><h1><span id="cactus">Cactus</span></h1><p><a href="https://github.com/koenbok/Cactus/" target="_blank" rel="noopener">Cactus</a>是使用Python和Django模版系统制作的静态网站生成工具。</p><p>Cactus的源码托管在github：</p><p><img src="http://cdn.yiyouls.com/cactus.png" alt="Cactus"></p><blockquote><p>开始使用Cactus：<a href="https://github.com/koenbok/Cactus/" target="_blank" rel="noopener">https://github.com/koenbok/Cactus/</a></p></blockquote><hr><h1><span id="hubpress">HubPress</span></h1><p><a href="http://hubpress.io/" target="_blank" rel="noopener">HubPress</a>是开源的web应用，使用它可以允许你创建一个基于GitHub Pages的博客。HubPress的使用非常简单，你只需要fork这个项目到你的github，然后修改配置文件就可以了。</p><p><img src="http://cdn.yiyouls.com/hubpress.png" alt="HubPress"></p><blockquote><p>开始使用HubPress：<a href="https://github.com/HubPress/hubpress.io" target="_blank" rel="noopener">https://github.com/HubPress/hubpress.io</a></p></blockquote><hr><p>对于到底为什么要用这一个工具而不是另外一个，每个人都能讲出一大推理由．hexo的确是它们当中较为突出并广受欢迎的．至于我为什么要用它，我不想在这里搜肠刮肚列出一系列炫酷的名词，我不得不说，我当初在选工具的时候并没有做太多的调研，没有在这一大推工具中犯选择困难症．当时在我面前的只有jekyll和hexo，而我在试用之后果断选择了hexo，在接下来的文章中我会告诉你原因．</p><p><img src="http://cdn.yiyouls.com/choice.gif" alt=""></p><p>如果你觉得哪个工具是你更加喜欢的，请在下方评论区中介绍并说明原因，我迫不及待想试试它们的功能．</p>]]></content>
      
      
      <categories>
          
          <category> 建站 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态网站 </tag>
            
            <tag> 建站工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何在Github上免费开通一个Github Page作为个人主页</title>
      <link href="/%E5%A6%82%E4%BD%95%E5%9C%A8Github%E4%B8%8A%E5%85%8D%E8%B4%B9%E5%BC%80%E9%80%9A%E4%B8%80%E4%B8%AAGithub-Page%E4%BD%9C%E4%B8%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5.html"/>
      <url>/%E5%A6%82%E4%BD%95%E5%9C%A8Github%E4%B8%8A%E5%85%8D%E8%B4%B9%E5%BC%80%E9%80%9A%E4%B8%80%E4%B8%AAGithub-Page%E4%BD%9C%E4%B8%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5.html</url>
      
        <content type="html"><![CDATA[<p>为什么要选择在Github上建站，原因很简单，它是免费的．</p><p>只要你按照下面的六步走，就可以轻轻松松发布自己的网站，你不需要有任何关于编程或者网站建设的基础知识．所有的前提只是，你要有一个github账号．</p><a id="more"></a><p><img src="http://cdn.yiyouls.com/show_the_stuff.jpeg" alt=""></p><p>少啰嗦，先看东西</p><p><img src="http://cdn.yiyouls.com/applepds.png" alt=""></p><p>iPhone显示效果</p><p>iPad显示效果</p><p>iMac显示效果</p><p>Macbook显示效果</p><hr><div class="alert warning"><p>看到这里，如果觉得这个风格不合胃口，你也可以选择可以提前离场，因为接下来的许多配置都将和这个主题相关．</p></div><p>希望不被打脸．．．</p><p><img src="http://cdn.yiyouls.com/slap.gif" alt=""></p><p>如果你喜欢这样的网站风格，想一步步照样配置（我会把源码给你），或者只是想从这篇教程中汲取自己所需要的东西，作为自己建站参考，你都会发现，这个系列博文是可以带给你很多有用的信息的．总之，希望大家能够各得其所，各取所需．</p><p>为了给大家做出详细的讲解和展示，我会使用一个新的终端设备，把自己的仓库清空，以一种推倒重来的方式再现整个建站过程．</p><p><img src="http://cdn.yiyouls.com/domino.gif" alt=""></p><p>当你下定决心要建站的时候，你就开始面临一系列的选择．我在上个文章中就已经提到了大家会面临的第一个分叉路口．对于一个想要搭建<strong>个人博客</strong>系统的新手，我坚定地建议你采用Github托管的方式，原因很简单，它是免费的．</p><p>假定大家都知道Github是个什么东西，并且对它有着一种类似信仰的原始崇拜．</p><p><img src="http://cdn.yiyouls.com/codeape.gif" alt=""></p><p>你可以在Github上免费开通<a href="https://pages.github.com" target="_blank" rel="noopener">Github Page</a>，为你个人或者你的项目建立一个网站．<a href="https://pages.github.com" target="_blank" rel="noopener">Github Page</a>官方网站上有详细的介绍和操作流程．让我们开始操作吧．</p><blockquote><p>第一步．创建存储库 (repository)</p></blockquote><p>转到<a href="https://github.com/" target="_blank" rel="noopener">GitHub</a>并<a href="https://github.com/new" target="_blank" rel="noopener">创建一个</a>名为<em>username</em> .github.io <a href="https://github.com/new" target="_blank" rel="noopener">的新存储库</a>，其中<em>username</em>是你在GitHub上的用户名（或组织名称）。</p><p><img src="http://cdn.yiyouls.com/step1.png" alt=""></p><p>如果存储库的第一部分与您的用户名不完全匹配，则无法正常工作，因此请务必正确使用。</p><span class="highlight-text danger">*需要注意的是*</span><ol><li>在实际操作中你会发现，如果你有自己的独立域名，对新储存库的命名不需要遵循这么严格的规则．以我自己为例，我的Github用户名是yiyouls,　我给自己用来建立Github Page的新仓库命名为blog.　同样是可行的．</li><li>仓库属性也可以选择Public</li></ol><blockquote><p>第二步，进入储存库，转到设置(settings)</p></blockquote><p>在设置页面你可以对你的新储存库进行相关设置，你可以在这里设置你的GIthub Page特性，包括功能的开启与关闭，是否绑定定制域名(custom domain).</p><p><img src="http://cdn.yiyouls.com/pagedomain.png" alt=""></p><blockquote><p>第三步，下载使用Github桌面客户端(Github Desktop)</p></blockquote><p>GitHub Desktop是在macOS和Windows上使用Git和GitHub的好方法。（如果你不想使用Github客户端，你也可以直接在终端里通过<code>git</code>命令进行操作<sup><a href="#fn_1" id="reffn_1">1</a></sup>，我会把terminal的操作方法一并列出）</p><p><a href="https://desktop.github.com/" target="_blank" rel="noopener">下载GitHub桌面</a></p><p><img src="http://cdn.yiyouls.com/githubdesk.png" alt=""></p><blockquote><p>第四步，将储存库克隆到本地，用Github桌面客户端打开</p></blockquote><p>客户端完成安装后，返回我们刚建的储存库主页并刷新页面。单击“Set up in Desktop”按钮。当GitHub桌面应用程序打开时，保存项目。这样我们就把该储存库克隆到了本地．</p><span class="highlight-text danger">注意</span><ol><li><p>如果Github桌面客户端未能打开，你可以从电脑应用程序库找到它并启动，用户登录后，你可以看到你名下的所有储存库，找到我们新建的那个，手动克隆它．</p></li><li><p>如果你使用terminal操作，你首先需要<code>cd</code>到你准备存放你的项目的文件夹（一定要记得你存放的路径），通过下面的操作克隆你的刚建的储存库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/username/username.github.io</span><br></pre></td></tr></table></figure></li></ol><p><img src="http://cdn.yiyouls.com/clone.png" alt=""></p><blockquote><p>第五步，创建索引文件</p></blockquote><p>到这里，你的储存库尚未添加任何文件，你的网站也相应地空空如也．你需要添加索引文件</p><figure class="codeblock codeblock--tabbed"><figcaption><a href="https://pages.github.com" target="_blank" rel="noopener">index.html</a><ul class="tabs"><li class="tab active">html</li></ul></figcaption><div class="tabs-content"><figure class="highlight html" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">​    <span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Hello World<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>I'm hosted with GitHub Pages.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​</span><br></pre></td></tr></tbody></table></figure></div></figure><p>这样，你就在你的网站上添加了一行”hello world”</p><span class="highlight-text danger">注意</span><p>如果是使用terminal操作，你需要<code>cd</code>进入克隆出的文件，然后向文件夹里添加内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd username.github.io</span><br><span class="line"></span><br><span class="line">echo &quot;Hello World&quot; &gt; index.html</span><br></pre></td></tr></table></figure><blockquote><p>第六步，提交和发布</p></blockquote><p>输入存储库，提交更改，然后按发布按钮。</p><span class="highlight-text danger">注意</span><ol><li><p>你克隆下来的储存库在本地，你可以通过Finder或者资源管理器找到它，把新文件放进去，Github客户端就能够读取到这些改变啦．</p></li><li><p>如果你使用terminal终端，可以用<code>push</code>推送操作进行发布：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git add --all</span><br><span class="line"></span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line"></span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure></li></ol><p><img src="http://cdn.yiyouls.com/desktop-demo.gif" alt=""></p><p>到这里，你的网站就已经发布在了<em>username</em> .github.io这个网址．教程到此结束．</p><div class="alert success"><p>you made it!</p></div><p><img src="http://cdn.yiyouls.com/really.gif" alt=""></p><p>网站这么丑，能用它来干嘛</p><p><img src="http://cdn.yiyouls.com/ugly.gif" alt=""></p><p>的确是这样，我们的网站虽然已经发布，但它基本还是个没用的废物，因为到目前为止我们只给它添加了一个索引文件．如果想要实现更多丰富的功能（可能是一些必备的功能），你必须添加很多代码和文件进去．</p><p><img src="http://cdn.yiyouls.com/busy.gif" alt=""></p><p>那么问题来了，真的忍心让你一点点把所有功能实现的代码都敲进去吗？那么建站所耗费的时间成本也太大了．事实上，我们大可不必这样．我们的开源社区已经有了很多可爱的工具和框架供我们使用，免去我们许多许多繁杂的工作．</p><p><img src="http://cdn.yiyouls.com/foryou.gif" alt=""></p><p>那么下篇博文，我会跟大家介绍一些可以让你的网站瞬间高大上起来的那些可爱的开源工具．so stay tuned.</p><blockquote id="fn_1"><sup>1</sup>. 之所以要使用Githbub客户端，是因为它是一个非常便捷的git储存库管理工具，当我们开始使用jekyll这样的建站工具对网站进行功能升级的时候，单单通过终端显然是很麻烦的．<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
      
      
      <categories>
          
          <category> 建站 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Github </tag>
            
            <tag> Github Page </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用hexo在Github上免费搭建功能丰富的个人博客网站</title>
      <link href="/%E4%BD%BF%E7%94%A8hexo%E5%9C%A8Github%E4%B8%8A%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E5%8A%9F%E8%83%BD%E4%B8%B0%E5%AF%8C%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99.html"/>
      <url>/%E4%BD%BF%E7%94%A8hexo%E5%9C%A8Github%E4%B8%8A%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E5%8A%9F%E8%83%BD%E4%B8%B0%E5%AF%8C%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99.html</url>
      
        <content type="html"><![CDATA[<p>这个系列博文将带你一步步搭建起自己的个人博客网站，包含tranquilpeak主题模板配置，站内搜索，live2d插件，mathjax数学公式插件，＂千牛云＂云加速，＂畅言＂评论区添加，打赏设置等等高阶功能．</p><a id="more"></a><p>我会特别强调在配置过程中可能会遇到的各种坑，一些不应该出现的问题会让大家觉得焦头烂额，明明是跟大家一样一步步按教程走过来的，为什么还是会出现百思不得其解的错误．所以这也将会是一个详细的踩坑记录．</p><p><img src="http://cdn.yiyouls.com/what.gif" alt=""></p><p>我一共花了三天时间把所有功能配置齐全，其中大部分时间都在处理那些在网上找不到教程的个性化问题，例如，＂首页缩略图无法加载＂，＂浏览器Tab栏favicon图标不能显示＂，＂首页外链icon如何更改＂，＂云加速镜像网址与加速网址的区别＂等等问题，这些琐碎的bug耗费了我大量时间，让我走了不少弯路．我会在文章中尽可能列出你在建站的时候可能会遇到的种种问题．你也可以在我的文章下面留言，告诉我你还遇到了什么样的坑．</p><p><img src="http://cdn.yiyouls.com/sorry.gif" alt=""></p><p>本文中所讲的博客搭建方法能够让你完成一个功能丰富的个人博客网站，满足绝大部分的个人需求，并且，如果你按照这样的步骤走完，你可以完全零成本搭建自己的网站，所有的服务和插件都可以用到基本免费的版本．</p><p><img src="http://cdn.yiyouls.com/free.gif" alt=""></p><p>当然，如果需要个性化的定制，比如绑定自己域名（你要购买一个私有域名），或者数据流量过大（如果网站有那么大的流量，说明你的博客可以用来变现了，哈哈），你是需要为你的爱好买单的．当然对于那些有特殊需求和目的的专业用户或者企业，是不太适合我这里所介绍的hexo+Github的建站方式的．我在＂手把手＂教大家建立自己的博客网站的时候，会兼顾有个人域名的童鞋和没有个人域名的童鞋．不过，像千牛云／畅言这样的建站服务的前提是要求你有一个经过工信部备案的域名．如果你没有个人域名，就不能实现一些我会讲到的有趣功能．</p><p><img src="http://cdn.yiyouls.com/pity.gif" alt=""></p><p>我个人在建站的过程中搜索了无数篇的博文和教程，这些文章大多数都是琐碎的讲解，浅尝辄止，内容又经常是千篇一律．甚至有一些有博文作者的理解错误，我在参考这些文章的时候吃了不少的苦头．在我建站的过程中就暗暗告诉自己，等这一切都结束了，我一定要总结出自己所有的经验和教训，让后来人得以参考．当然，也有一些非常好的教程，在建站中给了我很大帮助和启发，没有它们，我是无论如何也无法把网站搭建起来的．纸上得来终觉浅，绝知此事要躬行．</p><p>it makes me feel like Caesar</p><p><img src="http://cdn.yiyouls.com/finalrest.gif" alt=""></p><p>相信大家建立个人博客的初衷都是为了好玩，不管你是一个文艺青年，想要分享自己的生活和热爱，或者你是个极客，想要拿博客网站练手，都可以把这个教程当做你走向更广阔世界的垫脚石，这篇文章能帮你认识很多有趣的方法和概念，快速掌握许多建站技能，希望每个人都能从中有所收获．要知道，保持好奇心是一个人永远年轻的秘诀．</p><p><img src="http://cdn.yiyouls.com/young.gif" alt=""></p><p>话不多说，让我们一起开始吧！希望你玩的开心．</p>]]></content>
      
      
      <categories>
          
          <category> 建站 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
            <tag> hexo </tag>
            
            <tag> 建站 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是深度学习(Deep Learning)？</title>
      <link href="/No%202%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F.html"/>
      <url>/No%202%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F.html</url>
      
        <content type="html"><![CDATA[<p>机器学习与深度学习基础教程</p><p>这篇文章将要回答什么是深度学习这个问题．</p><p>整个系列课程会涵盖深度学习领域的众多主题，我们会用很多篇文章来充分解释这些课题，以及它们的应用领域和技术实现。</p><a id="more"></a><p><img src="http://cdn.yiyouls.com/cover_1.jpg" alt="cover_1"></p><!-- toc --><ul><li><a href="#深度学习概念解析">深度学习概念解析</a><ul><li><a href="#什么是深度学习">什么是深度学习？</a></li><li><a href="#深度学习中的深度指的是什么">深度学习中的＂深度＂指的是什么？</a></li></ul></li></ul><!-- tocstop --><p><img src="http://cdn.yiyouls.com/image_2.png" alt="image_2"></p><h2><span id="深度学习概念解析">深度学习概念解析</span></h2><h3><span id="什么是深度学习">什么是深度学习？</span></h3><p>这篇文章将要回答什么是深度学习这个问题．</p><p>整个系列课程会涵盖深度学习领域的众多主题，我们会用很多篇文章来充分解释这些课题，以及它们的应用领域和技术实现。</p><p>在这个深度学习系列中所有的文章按特定顺序发表，一些文章中某些概念是基于之前讨论过的概念之上，因此如果你还不熟悉我们正在使用的某些术语或示例，请务必查看先前的文章。</p><p>让我们给出深度学习的定义。</p><blockquote><p>深度学习是机器学习的一个子领域，它所使用的算法是由人类大脑神经网络结构和功能所启发。</p></blockquote><p>我们现在所讲的深度学习，同样采用从数据中学习的算法，就像我们在上一篇关于机器学习的文章中所讨论的那样。 然而，这里的学习算法或模型是基于大脑神经网络的结构和功能。</p><p>我们在深度学习中使用的神经网络不是真正的生物神经网络。 他们只是与生物神经网络共享一些特征，因此，我们称之为人工神经网络（ANNs）。</p><p>我们也经常使用其他术语来指代人工神经网络。 在深度学习领域，人工神经网络（ANN）这个术语有时候也用下面的一些表达：</p><ul><li>网络(net)</li><li>神经网络(neural net)</li><li>模型(model)</li></ul><p><img src="http://cdn.yiyouls.com/layers.png" alt="a simple artificial neural network or ANN"></p><h3><span id="深度学习中的深度指的是什么">深度学习中的＂深度＂指的是什么？</span></h3><p>要理解深度学习中的＂深度＂指的是什么，我们首先需要了解人工神经网络的结构。 我们会发现，深度学习使用了一种我们称之为深网(deep net)或深层人工神经网络(deep artificial neural network)的特殊人工神经网络。</p><p>在下一篇关于人工神经网络的文章中，我们将学习如何构建人工神经网络，这将为我们提供理解人工神经网络如何成为深度人工神经网络所需的知识。</p><p>现在，你需要了解以下内容：</p><ol><li>ANN是使用我们称之为神经元的方法构建的</li><li>人工神经网络中的神经元通过层(layer)的方法构建。</li><li>ANN中除了输入层(input layer)和输出层(output layer)之外的所有层都称为隐藏层(hidden layers)。</li><li>如果ANN具有多个隐藏层，则称该ANN为深度ANN</li></ol><p><img src="http://cdn.yiyouls.com/layers4.png" alt="deep neural network with 4 layers"></p><p>总结一下，深度学习使用具有多个隐藏层的ANN结构。 在学习过程中请牢记这一点，随着我们对深度学习理解的加深，我们会越来越明白这一点。 期待下个文章跟你相遇！</p><span class="highlight-text purple">公众微信：友邻学社关注获取更多内容</span><p><img src="http://cdn.yiyouls.com/qrcode.jpg" alt=""></p><div class="alert success"><p>You made it! keep up the good work ^_^</p></div>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是机器学习(Machine Learning)？</title>
      <link href="/No%201%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"/>
      <url>/No%201%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html</url>
      
        <content type="html"><![CDATA[<p>机器学习与深度学习基础教程－从零开始</p><p>本系列教程是为初学者定制，涵盖并解释了深度学习和人工神经网络的基本概念</p><a id="more"></a><p><img src="http://cdn.yiyouls.com/cover_1.jpg" alt="cover_1"></p><!-- toc --><ul><li><a href="#什么是机器学习">什么是机器学习？</a><ul><li><a href="#初识深度学习与人工神经网络">初识深度学习与人工神经网络</a></li><li><a href="#什么是机器学习-1">什么是机器学习？</a></li><li><a href="#机器学习-vs-传统编程">机器学习　v.s.　传统编程</a></li><li><a href="#更进一步深度学习">更进一步：深度学习</a></li></ul></li></ul><!-- tocstop --><p><img src="http://cdn.yiyouls.com/image_1.png" alt="image_1"></p><h2><span id="什么是机器学习">什么是机器学习？</span></h2><h3><span id="初识深度学习与人工神经网络">初识深度学习与人工神经网络</span></h3><p>本系列教程是为初学者定制，涵盖并解释了深度学习和人工神经网络的基本概念。</p><p>除了讲清基本概念，我们还展示了如何使用Keras（一种用Python编写的神经网络API）在代码中实现这些概念。 我们将学习人工神经网络中的层(layer)的概念，以及激活函数(activation function)，反向传播(backpropagation)，卷积神经网络（CNN），数据增强(data augmentation)，转移学习等概念。</p><p>我们通过讨论不同的术语，认识并理解它们的含义，搞清楚它们是如何适应整个深度学习框架的。 在某些章节里，我们会教大家如何在代码中实现一些课题。</p><p>我们会用Python编写的Keras神经网络API来进行演示，展示这些基本课题的技术实现。</p><p><img src="http://cdn.yiyouls.com/keras.png" alt="keras logo"></p><p>本网站有一个单独的系列专门介绍如何使用Keras，给大家作为重要参考。 Keras系列中的许多内容都假定你已经对本系列中将要讨论的深度学习知识有了基本的了解，请先浏览这个基础教程。</p><p>如果你想研究我们在本系列中所做的代码实现，可以转到Keras系列教程中了解Keras的预备知识，掌握这些先决知识，以便更好地使用Keras。</p><h3><span id="什么是机器学习">什么是机器学习？</span></h3><p>让我们从最基础的讲起。</p><p>深度学习是我们课程的核心概念，我们需要从基础着手更深入地认识它的含义。 在了解深度学习之前，我们首先要了解什么是机器学习。</p><blockquote><p>机器学习是使用算法分析数据，从该数据中学习，然后对新数据进行确定或预测的实践。</p></blockquote><p>这个概念听起来好像跟我们平常用写的代码差不多，似乎也是下面的路数：</p><ol><li>设计一个算法</li><li>机器在一个特定的数据集上执行这个算法</li><li>然后机器就可以在从未见过的新数据上再次执行这个任务</li></ol><p>都是给计算机下指令，那机器学习和我们平常写的逻辑算法区别在哪里呢？</p><p>根据我们刚刚给出的机器学习定义，重心是在＂从数据中学习＂这个部分．</p><blockquote><p>learn from data</p></blockquote><p>通过机器学习，而不是手动编写具有特定指令集的代码来完成特定任务，机器使用数据和算法进行训练，使其能够自主执行任务而无需明确告知如何执行任务。</p><p>现在这可能听起来像天方夜谭，但我们会在后面的文章中看到它是如何一步步实现的。 为了区别使用机器学习和传统编程来完成一项工作，我们看下面的示例。</p><p><img src="http://cdn.yiyouls.com/robot.jpg" alt="toy robot with a winder on its head and gears for ears (/home/scott/Documents/blog/source/_posts/robot%20machine.jpg)"></p><h3><span id="机器学习-vs-传统编程">机器学习　v.s.　传统编程</span></h3><p>示例：分析一个大众社交平台的评论，把这些评论分类为正面或负面情绪。</p><p><strong>传统的编程方法</strong><br>该算法可以首先查找与负面或正面情绪相关联的特定单词。</p><p>使用条件语句，算法会基于所查找到的正面或负面单词数目比例，将文章分类为正面或负面评价。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//伪代码</span></span><br><span class="line">let positive = [</span><br><span class="line">    <span class="string">"happy"</span>, </span><br><span class="line">    <span class="string">"thankful"</span>, </span><br><span class="line">    <span class="string">"amazing"</span></span><br><span class="line">];</span><br><span class="line"></span><br><span class="line">let negative = [</span><br><span class="line">    <span class="string">"can't"</span>, </span><br><span class="line">    <span class="string">"won't"</span>, </span><br><span class="line">    <span class="string">"sorry"</span>, </span><br><span class="line">    <span class="string">"unfortunately"</span></span><br><span class="line">];</span><br></pre></td></tr></table></figure><p>这些词汇的选择是程序员任意指定的。 一旦我们得到正面和负面单词的列表，一个简单的算法就是简单地计算给定文章中每种类型单词的出现次数。 然后，基于正例或负例那种次数更多，可以将文章分类为正向或负向。</p><p><strong>机器学习方法</strong><br>该算法分析给定的媒体数据并学习能够将负面文章与正面文章分类的特征。</p><p>通过学到的知识，算法可以将新文章分类为正面或负面。 在这种情况下，设计机器学习程序不需要明确指定需要算法识别的单词。 相反，该算法将通过检验每篇文章的标签来“学习”某些单词是正面还是负面。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//伪代码</span></span><br><span class="line">let articles = [</span><br><span class="line">    &#123;</span><br><span class="line">        label: <span class="string">"positive"</span>,</span><br><span class="line">        data: <span class="string">"The lizard movie was great! I really liked..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        label: <span class="string">"positive"</span>,</span><br><span class="line">        data: <span class="string">"Awesome lizards! The color green is my fav..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        label: <span class="string">"negative"</span>,</span><br><span class="line">        data: <span class="string">"Total disaster! I never liked..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        label: <span class="string">"negative"</span>,</span><br><span class="line">        data: <span class="string">"Worst movie of all time!..."</span></span><br><span class="line">    &#125;</span><br><span class="line">];</span><br></pre></td></tr></table></figure><h3><span id="更进一步深度学习">更进一步：深度学习</span></h3><p>在我们大概了解机器学习之后，就能够在此基础上认识深度学习。 深度学习是一种可用于实现机器学习的工具或技术。 下一节我们将详细介绍深入学习，敬请期待。 希望我们的文章可以帮到你！</p><span class="highlight-text purple">公众微信：友邻学社关注获取更多内容</span><p><img src="http://cdn.yiyouls.com/qrcode.jpg" alt=""></p><div class="alert success"><p>You made it! keep up the good work ^_^</p></div>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
